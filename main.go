package main

import (
	"bufio"
	"crypto/rand"
	"crypto/sha256"
	"database/sql"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"os"
	"path/filepath"
	"regexp"
	"strconv"
	"strings"
	"time"

	_ "github.com/denisenkom/go-mssqldb"
	"github.com/fsnotify/fsnotify"
)

// =============================================================================
// GLOBAL VARIABLES
// =============================================================================

var db *sql.DB
var activeSessions = make(map[string]Session)

const (
	DEFAULT_PORT = "8080"
	DB_NAME      = "VPLAnalyzer"
	PAGE_SIZE    = 50
)

// Default users
var defaultUsers = map[string]string{
	"admin": "admin123",
	"user":  "vpl2024",
}

// =============================================================================
// DATABASE FUNCTIONS (SQL EXPRESS)
// =============================================================================

func connectDatabase() error {
	connectionString := "server=BLCKTLP\\SQLEXPRESS;database=VPLAnalyzer;integrated security=SSPI;encrypt=true;trustservercertificate=true"
	var err error
	db, err = sql.Open("mssql", connectionString)
	if err != nil {
		return fmt.Errorf("database connection failed: %v", err)
	}

	if err = db.Ping(); err != nil {
		return fmt.Errorf("database ping failed: %v", err)
	}

	log.Println("‚úÖ SQL Express connected successfully")
	return createDatabaseSchema()
}

func createDatabaseSchema() error {
	fmt.Println("admin123 hash:", hashPassword("admin123"))
	fmt.Println("vpl2024 hash:", hashPassword("vpl2024"))

	return initializeDefaultData()
}

func initializeDefaultData() error {
	// Create default users
	for username, password := range defaultUsers {
		hashedPassword := hashPassword(password)
		_, err := db.Exec("INSERT INTO users (username, password_hash) VALUES (?, ?)",
			username, hashedPassword)
		if err != nil && !strings.Contains(err.Error(), "duplicate") {
			return fmt.Errorf("failed to create user %s: %v", username, err)
		}
	}

	// Insert sample required parts
	sampleParts := []RequiredPart{
		{"V710_PROJECT", "18K811"},
		{"V710_PROJECT", "!MPZ3T-OR-NPZ3T!"},
		{"J74_PROJECT", "V04545"},
		{"J74_PROJECT", "!W123-OR-W456!"},
	}

	for _, part := range sampleParts {
		_, err := db.Exec("INSERT INTO required_parts (project_name, required_part) VALUES (?, ?)",
			part.ProjectName, part.RequiredPart)
		if err != nil && !strings.Contains(err.Error(), "duplicate") {
			log.Printf("Warning: could not insert required part: %v", err)
		}
	}

	log.Println("‚úÖ Database schema and default data initialized")
	return nil
}

func saveVPLIssues(date string, issues []VPLIssue) error {
	// Clear existing issues for this date
	_, err := db.Exec("DELETE FROM vpl_issues WHERE date = ?", date)
	if err != nil {
		return fmt.Errorf("failed to clear existing VPL issues: %v", err)
	}

	// Insert new issues
	for _, issue := range issues {
		_, err := db.Exec(`INSERT INTO vpl_issues 
			(date, vin, project, issue_type, old_part, new_part, missing_part, details) 
			VALUES (?, ?, ?, ?, ?, ?, ?, ?)`,
			issue.Date,
			issue.VIN,
			issue.Project,
			issue.IssueType,
			issue.OldPart,
			issue.NewPart,
			issue.MissingPart,
			issue.Details)
		if err != nil {
			return fmt.Errorf("failed to insert VPL issue: %v", err)
		}
	}

	log.Printf("‚úÖ Saved %d VPL issues for date %s", len(issues), date)
	return nil
}

func saveMasterDataIssues(date string, teiIssues, oslIssues []MasterDataIssue) error {
	// Clear existing issues for this date
	_, err := db.Exec("DELETE FROM masterdata_issues WHERE date = ?", date)
	if err != nil {
		return fmt.Errorf("failed to clear existing master data issues: %v", err)
	}

	// Combine TEI and OSL issues
	allIssues := append(teiIssues, oslIssues...)

	// Insert new issues
	for _, issue := range allIssues {
		_, err := db.Exec(`INSERT INTO masterdata_issues 
			(date, part_name, inner_ref, issue_type, expected, actual, details) 
			VALUES (?, ?, ?, ?, ?, ?, ?)`,
			issue.Date,
			issue.PartName,
			issue.InnerRef,
			issue.IssueType,
			issue.Expected,
			issue.Actual,
			issue.Details)
		if err != nil {
			return fmt.Errorf("failed to insert master data issue: %v", err)
		}
	}

	log.Printf("‚úÖ Saved %d master data issues for date %s", len(allIssues), date)
	return nil
}

func getRequiredPartsForProject(project string) ([]string, error) {
	rows, err := db.Query("SELECT required_part FROM required_parts WHERE project_name = ?", project)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var parts []string
	for rows.Next() {
		var part string
		if err := rows.Scan(&part); err != nil {
			continue
		}
		parts = append(parts, part)
	}

	return parts, nil
}

// =============================================================================
// SECURITY FUNCTIONS
// =============================================================================

func hashPassword(password string) string {
	hash := sha256.Sum256([]byte(password))
	return hex.EncodeToString(hash[:])
}

func generateToken() string {
	bytes := make([]byte, 32)
	rand.Read(bytes)
	return hex.EncodeToString(bytes)
}

func validateCredentials(username, password string) bool {
	var storedHash string
	err := db.QueryRow("SELECT password_hash FROM users WHERE username = ?", username).Scan(&storedHash)
	if err != nil {
		return false
	}

	hashedInput := hashPassword(password)
	return hashedInput == storedHash
}

func createSession(username string) string {
	token := generateToken()
	expiresAt := time.Now().Add(SESSION_HOURS * time.Hour)

	session := Session{
		Token:     token,
		Username:  username,
		CreatedAt: time.Now(),
		ExpiresAt: expiresAt,
	}

	activeSessions[token] = session

	_, err := db.Exec("INSERT INTO sessions (token, username, expires_at) VALUES (?, ?, ?)",
		token, username, expiresAt)
	if err != nil {
		log.Printf("‚ùå Session database save failed: %v", err)
		// Ama token'ƒ± yine de d√∂nd√ºr, memory'de var
	} else {
		log.Printf("‚úÖ Session saved to database: %s", token[:10]+"...")
	}

	return token
}

func validateSession(token string) bool {
	session, exists := activeSessions[token]
	if !exists {
		// Try to load from database
		var username string
		var expiresAt time.Time
		err := db.QueryRow("SELECT username, expires_at FROM sessions WHERE token = ?", token).
			Scan(&username, &expiresAt)
		if err != nil {
			return false
		}

		session = Session{Token: token, Username: username, ExpiresAt: expiresAt}
		activeSessions[token] = session
	}

	if time.Now().After(session.ExpiresAt) {
		delete(activeSessions, token)
		db.Exec("DELETE FROM sessions WHERE token = ?", token)
		return false
	}

	return true
}

func validateInput(input string) bool {
	if len(input) > 200 {
		return false
	}

	dangerous := []string{"<script", "<iframe", "javascript:", "vbscript:", "onload=", "onerror=", "'", "\"", ";", "--"}
	inputLower := strings.ToLower(input)

	for _, danger := range dangerous {
		if strings.Contains(inputLower, danger) {
			return false
		}
	}

	return true
}

// =============================================================================
// FILE FUNCTIONS
// =============================================================================

// VPL dosyasƒ± bulma - Format: VPLHVLTA202509101.TXT (sonda yyyymmdd1)
func findVPLFileForDate(date string) string {
	// "2025-09-10" -> "20250910"

	// VPL dosyalarƒ±nƒ± tara
	pattern := "./vpl_files/*.TXT"
	matches, err := filepath.Glob(pattern)
	if err != nil {
		log.Printf("Error scanning VPL files: %v", err)
		return ""
	}

	for _, match := range matches {
		filename := filepath.Base(match)
		extractedDate := extractDateFromVPLFileName(filename)

		if extractedDate == date {
			log.Printf("üìÑ Found VPL file: %s for date %s", filename, date)
			return match
		}
	}

	log.Printf("‚ö†Ô∏è No VPL file found for date: %s", date)
	return ""
}

// TEI dosyasƒ± bulma - Format: SAP_20250820-030102-646.TEI (ba≈üta SAP_yyyymmdd)
func findTEIFileForDate(date string) string {
	// "2025-08-20" -> "20250820"

	// TEI dosyalarƒ±nƒ± tara
	pattern := "./masterdata_files/*.TEI"
	matches, err := filepath.Glob(pattern)
	if err != nil {
		log.Printf("Error scanning TEI files: %v", err)
		return ""
	}

	for _, match := range matches {
		filename := filepath.Base(match)
		extractedDate := extractDateFromTEIFileName(filename)

		if extractedDate == date {
			log.Printf("üìÑ Found TEI file: %s for date %s", filename, date)
			return match
		}
	}

	log.Printf("‚ö†Ô∏è No TEI file found for date: %s", date)
	return ""
}

// OSL dosyasƒ± bulma - Format: SAP_20250820-030039-146.OSL (ba≈üta SAP_yyyymmdd)
func findOSLFileForDate(date string) string {
	// "2025-08-20" -> "20250820"

	// OSL dosyalarƒ±nƒ± tara
	pattern := "./masterdata_files/*.OSL"
	matches, err := filepath.Glob(pattern)
	if err != nil {
		log.Printf("Error scanning OSL files: %v", err)
		return ""
	}

	for _, match := range matches {
		filename := filepath.Base(match)
		extractedDate := extractDateFromOSLFileName(filename)

		if extractedDate == date {
			log.Printf("üìÑ Found OSL file: %s for date %s", filename, date)
			return match
		}
	}

	log.Printf("‚ö†Ô∏è No OSL file found for date: %s", date)
	return ""
}

// =============================================================================
// TARƒ∞H √áIKARMA FONKSƒ∞YONLARI
// =============================================================================

// VPL dosya adƒ±ndan tarih √ßƒ±karma - VPLHVLTA202509101.TXT -> 2025-09-10
func extractDateFromVPLFileName(filename string) string {
	// Regex: dosya sonunda 8 rakam + 1 rakam + .TXT
	re := regexp.MustCompile(`(\d{8})1\.TXT$`)
	submatch := re.FindStringSubmatch(strings.ToUpper(filename))

	if len(submatch) > 1 {
		dateStr := submatch[1] // yyyymmdd kƒ±smƒ±
		if len(dateStr) == 8 {
			// "20250910" -> "2025-09-10"
			return fmt.Sprintf("%s-%s-%s", dateStr[0:4], dateStr[4:6], dateStr[6:8])
		}
	}

	return ""
}

// TEI dosya adƒ±ndan tarih √ßƒ±karma - SAP_20250820-030102-646.TEI -> 2025-08-20
func extractDateFromTEIFileName(filename string) string {
	// Regex: SAP_ + 8 rakam ile ba≈ülayan
	re := regexp.MustCompile(`^SAP_(\d{8})`)
	submatch := re.FindStringSubmatch(strings.ToUpper(filename))

	if len(submatch) > 1 {
		dateStr := submatch[1] // yyyymmdd kƒ±smƒ±
		if len(dateStr) == 8 {
			// "20250820" -> "2025-08-20"
			return fmt.Sprintf("%s-%s-%s", dateStr[0:4], dateStr[4:6], dateStr[6:8])
		}
	}

	return ""
}

// OSL dosya adƒ±ndan tarih √ßƒ±karma - SAP_20250820-030039-146.OSL -> 2025-08-20
func extractDateFromOSLFileName(filename string) string {
	// Regex: SAP_ + 8 rakam ile ba≈ülayan
	re := regexp.MustCompile(`^SAP_(\d{8})`)
	submatch := re.FindStringSubmatch(strings.ToUpper(filename))

	if len(submatch) > 1 {
		dateStr := submatch[1] // yyyymmdd kƒ±smƒ±
		if len(dateStr) == 8 {
			// "20250820" -> "2025-08-20"
			return fmt.Sprintf("%s-%s-%s", dateStr[0:4], dateStr[4:6], dateStr[6:8])
		}
	}

	return ""
}

// =============================================================================
// DOSYA OKUMA FONKSƒ∞YONLARI
// =============================================================================

// VPL dosyasƒ± okuma
func readVPLFile(filePath string) ([]VPLRecord, error) {
	if filePath == "" {
		return nil, fmt.Errorf("VPL file not found")
	}

	file, err := os.Open(filePath)
	if err != nil {
		return nil, fmt.Errorf("failed to open VPL file: %v", err)
	}
	defer file.Close()

	var records []VPLRecord
	scanner := bufio.NewScanner(file)
	lineCount := 0

	for scanner.Scan() {
		lineCount++
		line := strings.TrimSpace(scanner.Text())

		if strings.HasPrefix(line, "VPLIST") {
			record, err := parseVPLRecord(line)
			if err == nil {
				records = append(records, record)
			} else {
				log.Printf("Warning: Failed to parse VPL line %d: %v", lineCount, err)
			}
		}
	}

	if err := scanner.Err(); err != nil {
		return nil, fmt.Errorf("error reading VPL file: %v", err)
	}

	log.Printf("üìä Read %d VPL records from %s", len(records), filepath.Base(filePath))
	return records, nil
}

// TEI dosyasƒ± okuma
func readTEIFile(filePath string) (map[string]TEIRecord, error) {
	if filePath == "" {
		return nil, fmt.Errorf("TEI file not found")
	}

	file, err := os.Open(filePath)
	if err != nil {
		return nil, fmt.Errorf("failed to open TEI file: %v", err)
	}
	defer file.Close()

	teiMap := make(map[string]TEIRecord)
	scanner := bufio.NewScanner(file)
	lineCount := 0
	successCount := 0

	for scanner.Scan() {
		lineCount++
		line := strings.TrimSpace(scanner.Text())

		if line == "" {
			continue
		}

		// TEI format: 9353      PZ3T 14B522 ND3JA6                 PZ3T14B522ND3JA6
		// Bo≈üluklarƒ± split et
		fields := strings.Fields(line)

		if len(fields) < 5 { // En az 5 field olmalƒ±: 9353, PZ3T, 14B522, ND3JA6, inner_ref
			log.Printf("Warning: Invalid TEI line %d (insufficient fields): %s", lineCount, line)
			continue
		}

		// Customer reference: field[1], field[2], field[3] (PZ3T 14B522 ND3JA6)
		customerRef := fmt.Sprintf("%s %s %s", fields[1], fields[2], fields[3])

		// Inner reference: field[4] (PZ3T14B522ND3JA6)
		innerRef := fields[4]

		// Part description varsa field[5]'den ba≈ülar
		partDescription := ""
		if len(fields) > 5 {
			partDescription = strings.Join(fields[5:], " ")
		}

		record := TEIRecord{
			CustomerReference: customerRef,
			InnerReference:    innerRef,
			PartDescription:   partDescription,
		}

		teiMap[customerRef] = record
		successCount++

		// Debug i√ßin ilk 5 kaydƒ± logla
		if successCount <= 5 {
			log.Printf("TEI mapping %d: '%s' -> '%s'", successCount, customerRef, innerRef)
		}
	}

	if err := scanner.Err(); err != nil {
		return nil, fmt.Errorf("error reading TEI file: %v", err)
	}

	log.Printf("üìä Read %d TEI records from %s (total lines: %d)", successCount, filepath.Base(filePath), lineCount)
	return teiMap, nil
}

func readOSLFile(filePath string) (map[string]map[string]string, error) {
	if filePath == "" {
		return nil, fmt.Errorf("OSL file not found")
	}

	file, err := os.Open(filePath)
	if err != nil {
		return nil, fmt.Errorf("failed to open OSL file: %v", err)
	}
	defer file.Close()

	oslMap := make(map[string]map[string]string)
	scanner := bufio.NewScanner(file)
	lineCount := 0
	successCount := 0

	for scanner.Scan() {
		lineCount++
		line := strings.TrimSpace(scanner.Text())

		if line == "" {
			continue
		}

		// OSL format: 9353      SZ3114B522TD3JA6      MODULE      CK      CK
		fields := strings.Fields(line)

		if len(fields) >= 4 {
			innerRef := strings.TrimSpace(fields[1])   // ƒ∞kinci column: inner reference
			paramName := strings.TrimSpace(fields[2])  // √ú√ß√ºnc√º column: parameter name
			paramValue := strings.TrimSpace(fields[3]) // D√∂rd√ºnc√º column: parameter value

			if oslMap[innerRef] == nil {
				oslMap[innerRef] = make(map[string]string)
			}

			oslMap[innerRef][paramName] = paramValue
			successCount++

			// Debug i√ßin ilk 5 kaydƒ± logla
			if successCount <= 5 {
				log.Printf("OSL mapping %d: '%s' -> %s = %s", successCount, innerRef, paramName, paramValue)
			}
		} else {
			log.Printf("Warning: Invalid OSL line %d: insufficient fields (%d)", lineCount, len(fields))
		}
	}

	if err := scanner.Err(); err != nil {
		return nil, fmt.Errorf("error reading OSL file: %v", err)
	}

	log.Printf("üìä Read %d OSL parameter records from %s (total lines: %d)", successCount, filepath.Base(filePath), lineCount)
	log.Printf("üìä OSL covers %d unique inner references", len(oslMap))
	return oslMap, nil
}

// =============================================================================
// YARDIMCI FONKSƒ∞YONLAR
// =============================================================================

// VPL satƒ±rƒ±nƒ± parse etme
func parseVPLRecord(line string) (VPLRecord, error) {

	line = strings.TrimPrefix(line, "VPLIST")

	vin := line[:VIN_LENGTH]
	remaining := strings.TrimSpace(line[VIN_LENGTH:])

	re := regexp.MustCompile(`^(\S+)\s+(\S+)\s+(\S+)\s+([\d.]+)`)
	matches := re.FindStringSubmatch(remaining)

	prefix := matches[1]
	base := matches[2]
	suffix := matches[3]
	quantity := matches[4]

	record := VPLRecord{
		VIN:      vin,
		Prefix:   prefix,
		Base:     base,
		Suffix:   suffix,
		Quantity: quantity,
		PartName: prefix + base + suffix,
	}

	// Detect project from VIN
	if strings.HasPrefix(record.VIN, TAN_PREFIX) {
		record.DetectedProject = "V710_PROJECT"
	} else if strings.HasPrefix(record.VIN, TAR_PREFIX) {
		record.DetectedProject = "J74_PROJECT"
	} else {
		record.DetectedProject = "SECRET_PROJECT"
	}

	return record, nil
}

// Dosya varlƒ±ƒüƒ±nƒ± kontrol etme
func fileExists(filePath string) bool {
	_, err := os.Stat(filePath)
	return !os.IsNotExist(err)
}

// Mevcut dosyalarƒ± listeleme (debug i√ßin)
func listAvailableFiles() {
	log.Println("üìÅ Available VPL files:")
	vplFiles, _ := filepath.Glob("./vpl_files/*.TXT")
	for _, file := range vplFiles {
		filename := filepath.Base(file)
		date := extractDateFromVPLFileName(filename)
		log.Printf("  - %s (Date: %s)", filename, date)
	}

	log.Println("üìÅ Available TEI files:")
	teiFiles, _ := filepath.Glob("./masterdata_files/*.TEI")
	for _, file := range teiFiles {
		filename := filepath.Base(file)
		date := extractDateFromTEIFileName(filename)
		log.Printf("  - %s (Date: %s)", filename, date)
	}

	log.Println("üìÅ Available OSL files:")
	oslFiles, _ := filepath.Glob("./masterdata_files/*.OSL")
	for _, file := range oslFiles {
		filename := filepath.Base(file)
		date := extractDateFromOSLFileName(filename)
		log.Printf("  - %s (Date: %s)", filename, date)
	}
}

// Belirli tarih i√ßin t√ºm dosyalarƒ± kontrol etme

// =============================================================================
// ANALYSIS FUNCTIONS (Main Logic - Single Pass Analysis)
// =============================================================================

func runCompleteAnalysis(date string) error {
	log.Printf("üöÄ Starting complete analysis for date: %s", date)
	startTime := time.Now()

	// 1. Find required files
	currentVPLFile := findVPLFileForDate(date)
	if currentVPLFile == "" {
		return fmt.Errorf("VPL file not found for date %s", date)
	}

	// Calculate previous date for VPL comparison
	parsedDate, err := time.Parse("2006-01-02", date)
	if err != nil {
		return fmt.Errorf("invalid date format: %v", err)
	}
	previousDate := parsedDate.AddDate(0, 0, -1).Format("2006-01-02")
	previousVPLFile := findVPLFileForDate(previousDate)

	teiFile := findTEIFileForDate(date)
	oslFile := findOSLFileForDate(date)

	// 2. Read VPL files and compare
	currentVPL, err := readVPLFile(currentVPLFile)
	if err != nil {
		return fmt.Errorf("failed to read current VPL: %v", err)
	}

	var vplIssues []VPLIssue
	if previousVPLFile != "" {
		previousVPL, err := readVPLFile(previousVPLFile)
		if err != nil {
			log.Printf("Warning: could not read previous VPL file: %v", err)
		} else {
			vplIssues = compareVPLFiles(date, previousVPL, currentVPL)
		}
	}

	// 3. Check missing required parts
	missingRequired := checkMissingRequiredParts(date, currentVPL)
	vplIssues = append(vplIssues, missingRequired...)

	// 4. Extract customer references from VPL for master data analysis
	customerRefs := extractCustomerReferences(currentVPL)

	var teiIssues []MasterDataIssue
	var oslIssues []MasterDataIssue

	// 5. TEI Analysis (if file exists)
	if teiFile != "" {
		teiRecords, err := readTEIFile(teiFile)
		if err != nil {
			log.Printf("Warning: failed to read TEI file: %v", err)
		} else {
			teiIssues = validateTEIReferences(date, customerRefs, teiRecords)

			// 6. OSL Analysis (if file exists and we have TEI data)
			if oslFile != "" {
				oslRecords, err := readOSLFile(oslFile)
				if err != nil {
					log.Printf("Warning: failed to read OSL file: %v", err)
				} else {
					innerRefs := extractInnerReferences(customerRefs, teiRecords)
					oslIssues = validateOSLParameters(date, innerRefs, oslRecords)
				}
			}
		}
	}

	// 7. Save all issues to database
	if err := saveVPLIssues(date, vplIssues); err != nil {
		return fmt.Errorf("failed to save VPL issues: %v", err)
	}

	if err := saveMasterDataIssues(date, teiIssues, oslIssues); err != nil {
		return fmt.Errorf("failed to save master data issues: %v", err)
	}

	processingTime := time.Since(startTime)
	log.Printf("‚úÖ Complete analysis finished in %v - VPL: %d issues, Master Data: %d issues",
		processingTime, len(vplIssues), len(teiIssues)+len(oslIssues))

	return nil
}

// VPL dosyalarƒ±nƒ± kar≈üƒ±la≈ütƒ±r ve detaylƒ± change analizi yap
func compareVPLFiles(date string, previousVPL, currentVPL []VPLRecord) []VPLIssue {
	var issues []VPLIssue

	// Create maps for easy lookup - VIN+PREFIX+BASE+SUFFIX combination
	prevMap := make(map[string]VPLRecord)
	currMap := make(map[string]VPLRecord)

	// Create separate maps for part component tracking
	prevPartMap := make(map[string]map[string]VPLRecord) // VIN -> PartName -> Record
	currPartMap := make(map[string]map[string]VPLRecord) // VIN -> PartName -> Record

	// Build previous maps
	for _, record := range previousVPL {
		key := record.VIN + "|" + record.PartName
		prevMap[key] = record

		if prevPartMap[record.VIN] == nil {
			prevPartMap[record.VIN] = make(map[string]VPLRecord)
		}
		prevPartMap[record.VIN][record.PartName] = record
	}

	// Build current maps
	for _, record := range currentVPL {
		key := record.VIN + "|" + record.PartName
		currMap[key] = record

		if currPartMap[record.VIN] == nil {
			currPartMap[record.VIN] = make(map[string]VPLRecord)
		}
		currPartMap[record.VIN][record.PartName] = record
	}

	// Find added parts (in current but not in previous)
	for key, currRecord := range currMap {
		if _, exists := prevMap[key]; !exists {
			// Check if this is a component change vs completely new part
			componentChange := findComponentChange(currRecord, prevPartMap[currRecord.VIN])

			if componentChange != "" {
				// This is a component change, not a new part
				issues = append(issues, VPLIssue{
					Date:      date,
					VIN:       currRecord.VIN,
					Project:   currRecord.DetectedProject,
					IssueType: componentChange, // PREFIX_CHANGED, BASE_CHANGED, SUFFIX_CHANGED
					OldPart:   getOldPartForChange(currRecord, prevPartMap[currRecord.VIN], componentChange),
					NewPart:   currRecord.PartName,
					Details:   fmt.Sprintf("%s changed", getComponentName(componentChange)),
				})
			} else {
				// Completely new part
				issues = append(issues, VPLIssue{
					Date:      date,
					VIN:       currRecord.VIN,
					Project:   currRecord.DetectedProject,
					IssueType: VPL_ISSUE_ADDED,
					NewPart:   currRecord.PartName,
					Details:   "Part added",
				})
			}
		}
	}

	// Find removed parts (in previous but not in current)
	for key, prevRecord := range prevMap {
		if _, exists := currMap[key]; !exists {
			// Check if this part was modified instead of removed
			if !isPartModified(prevRecord, currPartMap[prevRecord.VIN]) {
				issues = append(issues, VPLIssue{
					Date:      date,
					VIN:       prevRecord.VIN,
					Project:   prevRecord.DetectedProject,
					IssueType: VPL_ISSUE_REMOVED,
					OldPart:   prevRecord.PartName,
					Details:   "Part removed",
				})
			}
		}
	}

	log.Printf("üìä VPL Comparison: %d added, %d removed, %d prefix changed, %d base changed, %d suffix changed",
		countIssuesByType(issues, VPL_ISSUE_ADDED),
		countIssuesByType(issues, VPL_ISSUE_REMOVED),
		countIssuesByType(issues, "PREFIX_CHANGED"),
		countIssuesByType(issues, "BASE_CHANGED"),
		countIssuesByType(issues, "SUFFIX_CHANGED"))

	return issues
}

// Check if a part has component changes (PREFIX, BASE, or SUFFIX)
func findComponentChange(currentRecord VPLRecord, previousParts map[string]VPLRecord) string {
	if previousParts == nil {
		return "" // No previous parts for this VIN
	}

	// Check each previous part to see if any component matches
	for _, prevRecord := range previousParts {
		// Same PREFIX and BASE, different SUFFIX
		if currentRecord.Prefix == prevRecord.Prefix &&
			currentRecord.Base == prevRecord.Base &&
			currentRecord.Suffix != prevRecord.Suffix {
			return "SUFFIX_CHANGED"
		}

		// Same PREFIX and SUFFIX, different BASE
		if currentRecord.Prefix == prevRecord.Prefix &&
			currentRecord.Suffix == prevRecord.Suffix &&
			currentRecord.Base != prevRecord.Base {
			return "BASE_CHANGED"
		}

		// Same BASE and SUFFIX, different PREFIX
		if currentRecord.Base == prevRecord.Base &&
			currentRecord.Suffix == prevRecord.Suffix &&
			currentRecord.Prefix != prevRecord.Prefix {
			return "PREFIX_CHANGED"
		}
	}

	return "" // No component change found
}

// Get the old part name that corresponds to the component change
func getOldPartForChange(currentRecord VPLRecord, previousParts map[string]VPLRecord, changeType string) string {
	if previousParts == nil {
		return ""
	}

	for _, prevRecord := range previousParts {
		switch changeType {
		case "SUFFIX_CHANGED":
			if currentRecord.Prefix == prevRecord.Prefix && currentRecord.Base == prevRecord.Base {
				return prevRecord.PartName
			}
		case "BASE_CHANGED":
			if currentRecord.Prefix == prevRecord.Prefix && currentRecord.Suffix == prevRecord.Suffix {
				return prevRecord.PartName
			}
		case "PREFIX_CHANGED":
			if currentRecord.Base == prevRecord.Base && currentRecord.Suffix == prevRecord.Suffix {
				return prevRecord.PartName
			}
		}
	}

	return ""
}

// Check if a part was modified (component change) rather than completely removed
func isPartModified(removedRecord VPLRecord, currentParts map[string]VPLRecord) bool {
	if currentParts == nil {
		return false
	}

	for _, currRecord := range currentParts {
		// Check if any current part shares components with removed part
		sameComponents := 0
		if removedRecord.Prefix == currRecord.Prefix {
			sameComponents++
		}
		if removedRecord.Base == currRecord.Base {
			sameComponents++
		}
		if removedRecord.Suffix == currRecord.Suffix {
			sameComponents++
		}

		// If 2 out of 3 components match, it's a modification
		if sameComponents >= 2 {
			return true
		}
	}

	return false
}

// Get component name for display
func getComponentName(changeType string) string {
	switch changeType {
	case "PREFIX_CHANGED":
		return "PREFIX"
	case "BASE_CHANGED":
		return "BASE"
	case "SUFFIX_CHANGED":
		return "SUFFIX"
	default:
		return "UNKNOWN"
	}
}

// Update types.go - add new issue types

// Update frontend conversion function

func checkMissingRequiredParts(date string, vplRecords []VPLRecord) []VPLIssue {
	var issues []VPLIssue

	// Group VPL records by project
	projectRecords := make(map[string][]VPLRecord)
	for _, record := range vplRecords {
		projectRecords[record.DetectedProject] = append(projectRecords[record.DetectedProject], record)
	}

	// Check each project
	for project, records := range projectRecords {
		requiredParts, err := getRequiredPartsForProject(project)
		if err != nil {
			log.Printf("Warning: could not get required parts for project %s: %v", project, err)
			continue
		}

		// Group records by VIN
		vinRecords := make(map[string][]VPLRecord)
		for _, record := range records {
			vinRecords[record.VIN] = append(vinRecords[record.VIN], record)
		}

		// Check each VIN for missing required parts
		for vin, vinParts := range vinRecords {
			for _, requiredPart := range requiredParts {
				if !hasRequiredPart(vinParts, requiredPart) {
					issues = append(issues, VPLIssue{
						Date:        date,
						VIN:         vin,
						Project:     project,
						IssueType:   VPL_ISSUE_MISSING_REQ,
						MissingPart: requiredPart,
						Details:     fmt.Sprintf("Missing required part: %s", requiredPart),
					})
				}
			}
		}
	}

	log.Printf("üìä Missing Required Parts: %d issues found", len(issues))
	return issues
}

func hasRequiredPart(vinParts []VPLRecord, requiredPart string) bool {
	// Handle OR groups: !A-OR-B!
	if strings.HasPrefix(requiredPart, "!") && strings.HasSuffix(requiredPart, "!") {
		orParts := strings.Split(strings.Trim(requiredPart, "!"), "-OR-")
		for _, orPart := range orParts {
			orPart = strings.TrimSpace(orPart)
			for _, vinPart := range vinParts {
				if strings.Contains(vinPart.PartName, orPart) {
					return true
				}
			}
		}
		return false
	}

	// Handle single part
	for _, vinPart := range vinParts {
		if strings.Contains(vinPart.PartName, requiredPart) {
			return true
		}
	}

	return false
}

var seen = make(map[string]bool)

// VPL record'dan doƒüru customer reference √ßƒ±karma
func extractCustomerReferences(vplRecords []VPLRecord) []string {
	var customerRefs []string
	seen := make(map[string]bool)

	for _, record := range vplRecords {
		// ‚úÖ FIX: VPL'deki PREFIX + BASE + SUFFIX formatƒ±nƒ± kullan
		// √ñnceki: "MPZ31 13A756 AA" formatƒ±nda
		// ≈ûimdi: Doƒüru format ile
		customerRef := fmt.Sprintf("%s %s %s", record.Prefix, record.Base, record.Suffix)

		if !seen[customerRef] {
			customerRefs = append(customerRefs, customerRef)
			seen[customerRef] = true

			// Debug i√ßin ilk 10'u logla
			if len(customerRefs) <= 10 {
				log.Printf("VPL Customer Ref extracted %d: '%s' (Prefix:'%s' Base:'%s' Suffix:'%s')",
					len(customerRefs), customerRef, record.Prefix, record.Base, record.Suffix)
			}
		}
	}

	log.Printf("üìä Extracted %d unique customer references from %d VPL records", len(customerRefs), len(vplRecords))
	return customerRefs
}
func formatCustomerReference(partName string) string {
	// Convert "MPZ3T18K811CF3JA6" to "MPZ3T 18K811 CF3JA6" format
	if len(partName) < 10 {
		return partName
	}

	// Simple formatting - can be enhanced based on actual format rules
	prefix := partName[:5]
	base := partName[5:11]
	suffix := partName[11:]

	return fmt.Sprintf("%s %s %s", prefix, base, suffix)
}

func validateTEIReferences(date string, customerRefs []string, teiRecords map[string]TEIRecord) []MasterDataIssue {
	var issues []MasterDataIssue
	foundCount := 0

	log.Printf("üîç Starting TEI validation for %d customer references against %d TEI records", len(customerRefs), len(teiRecords))

	for i, customerRef := range customerRefs {
		// Debug i√ßin ilk 5 kontrol√º logla
		if i < 5 {
			log.Printf("Checking TEI for customer ref %d: '%s'", i+1, customerRef)
		}

		teiRecord, exists := teiRecords[customerRef]
		if !exists {
			issues = append(issues, MasterDataIssue{
				Date:      date,
				PartName:  strings.ReplaceAll(customerRef, " ", ""),
				IssueType: MD_ISSUE_TEI_NOT_FOUND,
				Expected:  customerRef,
				Details:   "Customer reference not found in TEI file",
			})

			if i < 5 {
				log.Printf("  ‚ùå Not found in TEI: '%s'", customerRef)
			}
			continue
		}

		foundCount++
		if i < 5 {
			log.Printf("  ‚úÖ Found in TEI: '%s' -> '%s'", customerRef, teiRecord.InnerReference)
		}

		// Inner reference format kontrol√º
		expectedInner := generateExpectedInnerReference(customerRef)
		if teiRecord.InnerReference != expectedInner {
			issues = append(issues, MasterDataIssue{
				Date:      date,
				PartName:  strings.ReplaceAll(customerRef, " ", ""),
				InnerRef:  teiRecord.InnerReference,
				IssueType: MD_ISSUE_INNER_MISMATCH,
				Expected:  expectedInner,
				Actual:    teiRecord.InnerReference,
				Details:   "Inner reference format mismatch",
			})
		}

		// Description kontrol√º
		if strings.TrimSpace(teiRecord.PartDescription) == "" {
			issues = append(issues, MasterDataIssue{
				Date:      date,
				PartName:  strings.ReplaceAll(customerRef, " ", ""),
				InnerRef:  teiRecord.InnerReference,
				IssueType: MD_ISSUE_NO_DESCRIPTION,
				Details:   "Part description is missing",
			})
		}
	}

	log.Printf("üìä TEI Validation: %d found, %d issues found", foundCount, len(issues))
	return issues
}

func generateExpectedInnerReference(customerRef string) string {
	// "PZ3T 14B522 ND3JA6" -> "PZ3T14B522ND3JA6" (bo≈üluklarƒ± kaldƒ±r)
	cleaned := strings.ReplaceAll(customerRef, " ", "")

	// W ile ba≈ülayanlar i√ßin E prefix ekle

	// Diƒüerleri i√ßin direkt return
	return cleaned
}

func extractInnerReferences(customerRefs []string, teiRecords map[string]TEIRecord) []string {
	var innerRefs []string
	seen := make(map[string]bool)
	foundCount := 0

	log.Printf("üîç Extracting inner references from %d customer refs and %d TEI records", len(customerRefs), len(teiRecords))

	for _, customerRef := range customerRefs {
		if teiRecord, exists := teiRecords[customerRef]; exists {
			if !seen[teiRecord.InnerReference] {
				innerRefs = append(innerRefs, teiRecord.InnerReference)
				seen[teiRecord.InnerReference] = true
				foundCount++

				// Debug i√ßin ilk 5'i logla
				if foundCount <= 5 {
					log.Printf("Inner ref %d: '%s' -> '%s'", foundCount, customerRef, teiRecord.InnerReference)
				}
			}
		}
	}

	log.Printf("üìä Extracted %d unique inner references", len(innerRefs))
	return innerRefs
}

func validateOSLParameters(date string, innerRefs []string, oslRecords map[string]map[string]string) []MasterDataIssue {
	var issues []MasterDataIssue
	foundCount := 0

	log.Printf("üîç Starting OSL validation for %d inner references against %d OSL records", len(innerRefs), len(oslRecords))

	for i, innerRef := range innerRefs {
		// Debug i√ßin ilk 5 kontrol√º logla
		if i < 5 {
			log.Printf("Checking OSL for inner ref %d: '%s'", i+1, innerRef)
		}

		params, exists := oslRecords[innerRef]
		if !exists {
			issues = append(issues, MasterDataIssue{
				Date:      date,
				PartName:  innerRef,
				InnerRef:  innerRef,
				IssueType: MD_ISSUE_OSL_NOT_FOUND,
				Details:   "Inner reference not found in OSL file",
			})

			if i < 5 {
				log.Printf("  ‚ùå Not found in OSL: '%s'", innerRef)
			}
			continue
		}

		foundCount++
		if i < 5 {
			log.Printf("  ‚úÖ Found in OSL: '%s' (params: %d)", innerRef, len(params))
		}

		// Required parametreleri kontrol et
		requiredParams := []string{"MODULE", "PART_FAMILY"}
		var missingParams []string

		for _, param := range requiredParams {
			if value, exists := params[param]; !exists || strings.TrimSpace(value) == "" {
				missingParams = append(missingParams, param)
			}
		}

		if len(missingParams) > 0 {
			issues = append(issues, MasterDataIssue{
				Date:      date,
				PartName:  innerRef,
				InnerRef:  innerRef,
				IssueType: MD_ISSUE_MISSING_PARAMS,
				Expected:  strings.Join(requiredParams, ", "),
				Actual:    strings.Join(missingParams, ", "),
				Details:   fmt.Sprintf("Missing required parameters: %s", strings.Join(missingParams, ", ")),
			})
		}

		// CK mod√ºl√º √∂zel kurallarƒ±
		if moduleValue, exists := params["MODULE"]; exists && strings.ToUpper(strings.TrimSpace(moduleValue)) == "CK" {
			ckRequiredParams := []string{"LABEL_POSITION", "LABEL_TYPE"}
			var missingCKParams []string

			for _, ckParam := range ckRequiredParams {
				if value, exists := params[ckParam]; !exists || strings.TrimSpace(value) == "" {
					missingCKParams = append(missingCKParams, ckParam)
				}
			}

			if len(missingCKParams) > 0 {
				issues = append(issues, MasterDataIssue{
					Date:      date,
					PartName:  innerRef,
					InnerRef:  innerRef,
					IssueType: MD_ISSUE_CK_VIOLATION,
					Expected:  strings.Join(ckRequiredParams, ", "),
					Actual:    strings.Join(missingCKParams, ", "),
					Details:   fmt.Sprintf("CK module missing parameters: %s", strings.Join(missingCKParams, ", ")),
				})
			}
		}
	}

	log.Printf("üìä OSL Validation: %d found, %d issues found", foundCount, len(issues))
	return issues
}

func countIssuesByType(issues []VPLIssue, issueType string) int {
	count := 0
	for _, issue := range issues {
		if issue.IssueType == issueType {
			count++
		}
	}
	return count
}

// =============================================================================
// HTTP FUNCTIONS
// =============================================================================

func setupRoutes() {
	// Static files
	http.HandleFunc("/", handleStaticFiles)
	http.HandleFunc("/login", handleStaticFiles)
	http.Handle("/assets/", http.StripPrefix("/assets/", http.FileServer(http.Dir("./assets/"))))

	http.HandleFunc("/selection", requireAuth(handleStaticFiles))
	http.HandleFunc("/vpl-dashboard", requireAuth(handleStaticFiles))
	http.HandleFunc("/masterdata-dashboard", requireAuth(handleStaticFiles))
	http.HandleFunc("/config", requireAuth(handleStaticFiles))

	// Authentication API
	http.HandleFunc("/api/login", handleLogin)
	http.HandleFunc("/api/logout", handleLogout)

	// VPL Analysis API
	http.HandleFunc("/api/vpl/summary/", requireAuth(handleVPLSummary))
	http.HandleFunc("/api/vpl/issues/", requireAuth(handleVPLIssues))
	http.HandleFunc("/api/vpl/search", requireAuth(handleVPLSearch))

	// Master Data API
	http.HandleFunc("/api/masterdata/summary/", requireAuth(handleMasterDataSummary))
	http.HandleFunc("/api/masterdata/issues/", requireAuth(handleMasterDataIssues))
	http.HandleFunc("/api/masterdata/search", requireAuth(handleMasterDataSearch))

	// Configuration API
	http.HandleFunc("/api/required-parts/", requireAuth(handleRequiredParts))
	http.HandleFunc("/api/system/health", requireAuth(handleSystemHealth))
	// VPL Analysis endpoint (frontend'in beklediƒüi)
	http.HandleFunc("/api/analysis/", requireAuth(handleVPLAnalysis))

	// Masterdata Analysis endpoint
	http.HandleFunc("/api/masterdata/analysis/", requireAuth(handleMasterDataAnalysis))
	http.HandleFunc("/api/masterdata/manual-analysis", requireAuth(handleMasterDataManualAnalysis))

	// Manuel analiz endpoint
	http.HandleFunc("/api/vpl/analyze", requireAuth(handleManualVPLAnalysis))

	// Reanalyze endpoints
	http.HandleFunc("/api/reanalyze", requireAuth(handleReanalyze))
	http.HandleFunc("/api/masterdata/reanalyze", requireAuth(handleMasterDataReanalyze))

	log.Println("‚úÖ HTTP routes configured")
}
func requireAuth(handler http.HandlerFunc) http.HandlerFunc {
	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		log.Printf("üîç Auth check for URL: %s", r.URL.Path)

		cookie, err := r.Cookie("session_token")

		if err != nil || !validateSession(cookie.Value) {
			log.Printf("‚ùå No session cookie found: %v", err)
			http.Redirect(w, r, "/login", http.StatusSeeOther)
			return
		}
		log.Printf("‚úÖ Cookie found, calling handler")

		handler(w, r)
	})
}

func handleStaticFiles(w http.ResponseWriter, r *http.Request) {
	switch r.URL.Path {
	case "/", "/login":
		http.ServeFile(w, r, "frontend/login.html")
	case "/selection":
		http.ServeFile(w, r, "frontend/selection.html")
	case "/vpl-dashboard":
		http.ServeFile(w, r, "frontend/vpl-dashboard.html")
	case "/masterdata-dashboard":
		http.ServeFile(w, r, "frontend/masterdata_dashboard.html")
	case "/config":
		http.ServeFile(w, r, "frontend/config.html")
	default:
		http.NotFound(w, r)
	}
}

func handleLogin(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		sendError(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	var loginReq struct {
		Username string `json:"username"`
		Password string `json:"password"`
	}

	if err := json.NewDecoder(r.Body).Decode(&loginReq); err != nil {
		sendError(w, "Invalid request format", http.StatusBadRequest)
		return
	}

	if !validateInput(loginReq.Username) || !validateInput(loginReq.Password) {
		sendError(w, "Invalid input", http.StatusBadRequest)
		return
	}

	if validateCredentials(loginReq.Username, loginReq.Password) {
		token := createSession(loginReq.Username)

		http.SetCookie(w, &http.Cookie{
			Name:     "session_token",
			Value:    token,
			Path:     "/",
			MaxAge:   SESSION_HOURS * 3600,
			HttpOnly: true,
			SameSite: http.SameSiteStrictMode,
		})

		sendJSON(w, APIResponse{
			Success: true,
			Message: "Login successful",
		})

		log.Printf("‚úÖ User logged in: %s", loginReq.Username)
	} else {
		sendError(w, "Invalid credentials", http.StatusUnauthorized)
		log.Printf("‚ùå Failed login attempt: %s", loginReq.Username)
	}
}

func handleLogout(w http.ResponseWriter, r *http.Request) {
	cookie, err := r.Cookie("session_token")
	if err == nil {
		delete(activeSessions, cookie.Value)
		db.Exec("DELETE FROM sessions WHERE token = ?", cookie.Value)
	}

	http.SetCookie(w, &http.Cookie{
		Name:   "session_token",
		Value:  "",
		Path:   "/",
		MaxAge: -1,
	})

	sendJSON(w, APIResponse{Success: true, Message: "Logout successful"})
}

func handleVPLSummary(w http.ResponseWriter, r *http.Request) {
	date := strings.TrimPrefix(r.URL.Path, "/api/vpl/summary/")
	if date == "" || !validateInput(date) {
		sendError(w, "Invalid date parameter", http.StatusBadRequest)
		return
	}

	summary, err := getVPLAnalysisSummary(date)
	if err != nil {
		sendError(w, "Failed to get VPL summary", http.StatusInternalServerError)
		return
	}

	sendJSON(w, APIResponse{
		Success: true,
		Data:    summary,
	})
}

func handleVPLIssues(w http.ResponseWriter, r *http.Request) {
	date := strings.TrimPrefix(r.URL.Path, "/api/vpl/issues/")
	if date == "" || !validateInput(date) {
		sendError(w, "Invalid date parameter", http.StatusBadRequest)
		return
	}

	page := 1
	if pageStr := r.URL.Query().Get("page"); pageStr != "" {
		if p, err := strconv.Atoi(pageStr); err == nil && p > 0 {
			page = p
		}
	}

	issues, total, err := getVPLIssues(date, page, PAGE_SIZE)
	if err != nil {
		sendError(w, "Failed to get VPL issues", http.StatusInternalServerError)
		return
	}

	modal := VPLIssuesModal{
		Issues:     issues,
		TotalCount: total,
		Page:       page,
		PageSize:   PAGE_SIZE,
	}

	sendJSON(w, APIResponse{
		Success: true,
		Data:    modal,
	})
}

func handleVPLSearch(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		sendError(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	var searchReq VPLIssuesSearchRequest
	if err := json.NewDecoder(r.Body).Decode(&searchReq); err != nil {
		sendError(w, "Invalid request format", http.StatusBadRequest)
		return
	}

	if !validateInput(searchReq.Date) || !validateInput(searchReq.Query) {
		sendError(w, "Invalid input", http.StatusBadRequest)
		return
	}

	issues, total, err := searchVPLIssues(searchReq)
	if err != nil {
		sendError(w, "Search failed", http.StatusInternalServerError)
		return
	}

	modal := VPLIssuesModal{
		Issues:      issues,
		TotalCount:  total,
		Page:        searchReq.Page,
		PageSize:    searchReq.PageSize,
		SearchQuery: searchReq.Query,
		FilterType:  searchReq.FilterType,
	}

	sendJSON(w, APIResponse{
		Success: true,
		Data:    modal,
	})
}

func handleRunAnalysis(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		sendError(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	var analysisReq struct {
		Date string `json:"date"`
	}

	if err := json.NewDecoder(r.Body).Decode(&analysisReq); err != nil {
		sendError(w, "Invalid request format", http.StatusBadRequest)
		return
	}

	if !validateInput(analysisReq.Date) {
		sendError(w, "Invalid date", http.StatusBadRequest)
		return
	}

	go func() {
		if err := runCompleteAnalysis(analysisReq.Date); err != nil {
			log.Printf("‚ùå Analysis failed for date %s: %v", analysisReq.Date, err)
		}
	}()

	sendJSON(w, APIResponse{
		Success: true,
		Message: "Analysis started",
	})
}

func handleMasterDataSummary(w http.ResponseWriter, r *http.Request) {
	date := strings.TrimPrefix(r.URL.Path, "/api/masterdata/summary/")
	if date == "" || !validateInput(date) {
		sendError(w, "Invalid date parameter", http.StatusBadRequest)
		return
	}

	summary, err := getMasterDataAnalysisSummary(date)
	if err != nil {
		sendError(w, "Failed to get master data summary", http.StatusInternalServerError)
		return
	}

	sendJSON(w, APIResponse{
		Success: true,
		Data:    summary,
	})
}
func handleMasterDataManualAnalysis(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		sendError(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	today := time.Now().Format("2006-01-02")

	log.Printf("üî® Manual masterdata analysis started for date: %s", today)

	// ‚úÖ √ñnce eski verileri temizle
	_, err := db.Exec("DELETE FROM masterdata_issues WHERE date = ?", today)
	if err != nil {
		log.Printf("‚ùå Failed to clear old masterdata: %v", err)
		sendError(w, "Failed to clear old data", http.StatusInternalServerError)
		return
	}
	log.Printf("üóëÔ∏è Cleared old masterdata for date: %s", today)

	// ‚úÖ Analizi SYNC olarak √ßalƒ±≈ütƒ±r
	if err := runCompleteAnalysis(today); err != nil {
		log.Printf("‚ùå Manual masterdata analysis failed: %v", err)
		sendError(w, "Analysis failed: "+err.Error(), http.StatusInternalServerError)
		return
	}

	log.Printf("‚úÖ Manual masterdata analysis completed for date: %s", today)

	sendJSON(w, APIResponse{
		Success: true,
		Message: "Manual masterdata analysis completed successfully",
		Data:    today,
	})
}

func handleMasterDataIssues(w http.ResponseWriter, r *http.Request) {
	date := strings.TrimPrefix(r.URL.Path, "/api/masterdata/issues/")
	if date == "" || !validateInput(date) {
		sendError(w, "Invalid date parameter", http.StatusBadRequest)
		return
	}

	page := 1
	if pageStr := r.URL.Query().Get("page"); pageStr != "" {
		if p, err := strconv.Atoi(pageStr); err == nil && p > 0 {
			page = p
		}
	}

	issues, total, err := getMasterDataIssues(date, page, PAGE_SIZE)
	if err != nil {
		sendError(w, "Failed to get master data issues", http.StatusInternalServerError)
		return
	}

	modal := MasterDataIssuesModal{
		Issues:     issues,
		TotalCount: total,
		Page:       page,
		PageSize:   PAGE_SIZE,
	}

	sendJSON(w, APIResponse{
		Success: true,
		Data:    modal,
	})
}

func handleMasterDataSearch(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		sendError(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	var searchReq MasterDataIssuesSearchRequest
	if err := json.NewDecoder(r.Body).Decode(&searchReq); err != nil {
		sendError(w, "Invalid request format", http.StatusBadRequest)
		return
	}

	if !validateInput(searchReq.Date) || !validateInput(searchReq.Query) {
		sendError(w, "Invalid input", http.StatusBadRequest)
		return
	}

	issues, total, err := searchMasterDataIssues(searchReq)
	if err != nil {
		sendError(w, "Search failed", http.StatusInternalServerError)
		return
	}

	modal := MasterDataIssuesModal{
		Issues:      issues,
		TotalCount:  total,
		Page:        searchReq.Page,
		PageSize:    searchReq.PageSize,
		SearchQuery: searchReq.Query,
		FilterType:  searchReq.FilterType,
	}

	sendJSON(w, APIResponse{
		Success: true,
		Data:    modal,
	})
}

func handleRequiredParts(w http.ResponseWriter, r *http.Request) {
	project := strings.TrimPrefix(r.URL.Path, "/api/required-parts/")
	if project == "" || !validateInput(project) {
		sendError(w, "Invalid project parameter", http.StatusBadRequest)
		return
	}

	switch r.Method {
	case "GET":
		parts, err := getRequiredPartsForProject(project)
		if err != nil {
			sendError(w, "Failed to get required parts", http.StatusInternalServerError)
			return
		}

		sendJSON(w, APIResponse{
			Success: true,
			Data:    parts,
		})

	case "POST":
		var req struct {
			Parts []string `json:"parts"`
		}

		if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
			sendError(w, "Invalid request format", http.StatusBadRequest)
			return
		}

		// Validate all parts
		for _, part := range req.Parts {
			if !validateInput(part) {
				sendError(w, "Invalid part format", http.StatusBadRequest)
				return
			}
		}

		if err := updateRequiredPartsForProject(project, req.Parts); err != nil {
			sendError(w, "Failed to update required parts", http.StatusInternalServerError)
			return
		}

		sendJSON(w, APIResponse{
			Success: true,
			Message: "Required parts updated successfully",
		})

	default:
		sendError(w, "Method not allowed", http.StatusMethodNotAllowed)
	}
}

func handleSystemHealth(w http.ResponseWriter, r *http.Request) {
	health := map[string]interface{}{
		"database":             "OK",
		"vpl_directory":        checkDirectory("./vpl_files"),
		"masterdata_directory": checkDirectory("./masterdata_files"),
		"active_sessions":      len(activeSessions),
		"timestamp":            time.Now().Format("2006-01-02 15:04:05"),
	}

	sendJSON(w, APIResponse{
		Success: true,
		Data:    health,
	})
}

// =============================================================================
// HELPER FUNCTIONS FOR HTTP HANDLERS
// =============================================================================

func getVPLAnalysisSummary(date string) (VPLAnalysisSummary, error) {
	var summary VPLAnalysisSummary
	summary.Date = date

	// Count total issues
	err := db.QueryRow("SELECT COUNT(*) FROM vpl_issues WHERE date = ?", date).Scan(&summary.IssuesFound)
	if err != nil {
		return summary, err
	}

	// Count by type
	db.QueryRow("SELECT COUNT(*) FROM vpl_issues WHERE date = ? AND issue_type IN (?, ?, ?)",
		date, VPL_ISSUE_ADDED, VPL_ISSUE_REMOVED, VPL_ISSUE_CHANGED).Scan(&summary.ChangesCount)

	db.QueryRow("SELECT COUNT(*) FROM vpl_issues WHERE date = ? AND issue_type = ?",
		date, VPL_ISSUE_MISSING_REQ).Scan(&summary.MissingReqCount)

	// Count affected VINs
	db.QueryRow("SELECT COUNT(DISTINCT vin) FROM vpl_issues WHERE date = ?", date).Scan(&summary.AffectedVINs)

	summary.HasIssues = summary.IssuesFound > 0
	summary.ProcessingTime = "2.3s" // This could be stored during analysis

	return summary, nil
}

func getMasterDataAnalysisSummary(date string) (MasterDataAnalysisSummary, error) {
	var summary MasterDataAnalysisSummary
	summary.Date = date

	// Count total issues
	err := db.QueryRow("SELECT COUNT(*) FROM masterdata_issues WHERE date = ?", date).Scan(&summary.IssuesFound)
	if err != nil {
		return summary, err
	}

	// Count by type
	db.QueryRow("SELECT COUNT(*) FROM masterdata_issues WHERE date = ? AND issue_type IN (?, ?, ?)",
		date, MD_ISSUE_TEI_NOT_FOUND, MD_ISSUE_INNER_MISMATCH, MD_ISSUE_NO_DESCRIPTION).Scan(&summary.TEIIssuesCount)

	db.QueryRow("SELECT COUNT(*) FROM masterdata_issues WHERE date = ? AND issue_type IN (?, ?)",
		date, MD_ISSUE_OSL_NOT_FOUND, MD_ISSUE_MISSING_PARAMS).Scan(&summary.OSLIssuesCount)

	db.QueryRow("SELECT COUNT(*) FROM masterdata_issues WHERE date = ? AND issue_type = ?",
		date, MD_ISSUE_CK_VIOLATION).Scan(&summary.CKViolationsCount)

	// Count affected parts
	db.QueryRow("SELECT COUNT(DISTINCT part_name) FROM masterdata_issues WHERE date = ?", date).Scan(&summary.AffectedPartsCount)

	summary.HasIssues = summary.IssuesFound > 0

	// Calculate compliance rate (assuming we track total parts analyzed)
	if summary.TotalPartsAnalyzed > 0 {
		summary.ComplianceRate = float64(summary.TotalPartsAnalyzed-summary.IssuesFound) / float64(summary.TotalPartsAnalyzed) * 100
	}

	return summary, nil
}

func getVPLIssues(date string, page, pageSize int) ([]VPLIssueDetail, int, error) {
	// Count total
	var total int
	err := db.QueryRow("SELECT COUNT(*) FROM vpl_issues WHERE date = ?", date).Scan(&total)
	if err != nil {
		return nil, 0, err
	}

	// Get paginated results
	offset := (page - 1) * pageSize
	rows, err := db.Query(`SELECT vin, project, issue_type, 
		ISNULL(old_part, '') as old_part, ISNULL(new_part, '') as new_part, 
		ISNULL(missing_part, '') as missing_part, ISNULL(details, '') as details
		FROM vpl_issues WHERE date = ? 
		ORDER BY id 
		OFFSET ? ROWS FETCH NEXT ? ROWS ONLY`,
		date, offset, pageSize)
	if err != nil {
		return nil, 0, err
	}
	defer rows.Close()

	var issues []VPLIssueDetail
	for rows.Next() {
		var issue VPLIssueDetail
		err := rows.Scan(&issue.VIN, &issue.Project, &issue.IssueType,
			&issue.OldPart, &issue.NewPart, &issue.MissingPart, &issue.Details)
		if err != nil {
			continue
		}
		issues = append(issues, issue)
	}

	return issues, total, nil
}

func getMasterDataIssues(date string, page, pageSize int) ([]MasterDataIssueDetail, int, error) {
	// Count total
	var total int
	err := db.QueryRow("SELECT COUNT(*) FROM masterdata_issues WHERE date = ?", date).Scan(&total)
	if err != nil {
		return nil, 0, err
	}

	// Get paginated results
	offset := (page - 1) * pageSize
	rows, err := db.Query(`SELECT part_name, ISNULL(inner_ref, '') as inner_ref, issue_type,
		ISNULL(expected, '') as expected, ISNULL(actual, '') as actual, 
		ISNULL(details, '') as details
		FROM masterdata_issues WHERE date = ? 
		ORDER BY id 
		OFFSET ? ROWS FETCH NEXT ? ROWS ONLY`,
		date, offset, pageSize)
	if err != nil {
		return nil, 0, err
	}
	defer rows.Close()

	var issues []MasterDataIssueDetail
	for rows.Next() {
		var issue MasterDataIssueDetail
		err := rows.Scan(&issue.PartName, &issue.InnerRef, &issue.IssueType,
			&issue.Expected, &issue.Actual, &issue.Details)
		if err != nil {
			continue
		}
		issues = append(issues, issue)
	}

	return issues, total, nil
}

func searchVPLIssues(req VPLIssuesSearchRequest) ([]VPLIssueDetail, int, error) {
	whereClause := "WHERE date = ?"
	args := []interface{}{req.Date}
	argIndex := 2

	// Add search filter
	if req.Query != "" {
		whereClause += fmt.Sprintf(" AND (vin LIKE @p%d OR old_part LIKE @p%d OR new_part LIKE @p%d OR missing_part LIKE @p%d)",
			argIndex, argIndex+1, argIndex+2, argIndex+3)
		searchPattern := "%" + req.Query + "%"
		args = append(args, searchPattern, searchPattern, searchPattern, searchPattern)
		argIndex += 4
	}

	// Add type filter
	if req.FilterType != "" && req.FilterType != "ALL" {
		switch req.FilterType {
		case "CHANGES":
			whereClause += fmt.Sprintf(" AND issue_type IN (@p%d, @p%d, @p%d)", argIndex, argIndex+1, argIndex+2)
			args = append(args, VPL_ISSUE_ADDED, VPL_ISSUE_REMOVED, VPL_ISSUE_CHANGED)
			argIndex += 3
		case "MISSING_REQ":
			whereClause += fmt.Sprintf(" AND issue_type = @p%d", argIndex)
			args = append(args, VPL_ISSUE_MISSING_REQ)
			argIndex++
		}
	}

	// Count total
	var total int
	countQuery := "SELECT COUNT(*) FROM vpl_issues " + whereClause
	err := db.QueryRow(countQuery, args...).Scan(&total)
	if err != nil {
		return nil, 0, err
	}

	// Get paginated results
	if req.Page <= 0 {
		req.Page = 1
	}
	if req.PageSize <= 0 {
		req.PageSize = PAGE_SIZE
	}

	offset := (req.Page - 1) * req.PageSize
	whereClause += fmt.Sprintf(" ORDER BY id OFFSET @p%d ROWS FETCH NEXT @p%d ROWS ONLY", argIndex, argIndex+1)
	args = append(args, offset, req.PageSize)

	selectQuery := `SELECT vin, project, issue_type, 
		ISNULL(old_part, '') as old_part, ISNULL(new_part, '') as new_part, 
		ISNULL(missing_part, '') as missing_part, ISNULL(details, '') as details
		FROM vpl_issues ` + whereClause

	rows, err := db.Query(selectQuery, args...)
	if err != nil {
		return nil, 0, err
	}
	defer rows.Close()

	var issues []VPLIssueDetail
	for rows.Next() {
		var issue VPLIssueDetail
		err := rows.Scan(&issue.VIN, &issue.Project, &issue.IssueType,
			&issue.OldPart, &issue.NewPart, &issue.MissingPart, &issue.Details)
		if err != nil {
			continue
		}

		// Add highlighting for search
		if req.Query != "" {
			issue.HighlightText = req.Query
		}

		issues = append(issues, issue)
	}

	return issues, total, nil
}

func searchMasterDataIssues(req MasterDataIssuesSearchRequest) ([]MasterDataIssueDetail, int, error) {
	whereClause := "WHERE date = ?"
	args := []interface{}{req.Date}
	argIndex := 2

	// Add search filter
	if req.Query != "" {
		whereClause += fmt.Sprintf(" AND (part_name LIKE @p%d OR inner_ref LIKE @p%d OR details LIKE @p%d)",
			argIndex, argIndex+1, argIndex+2)
		searchPattern := "%" + req.Query + "%"
		args = append(args, searchPattern, searchPattern, searchPattern)
		argIndex += 3
	}

	// Add type filter
	if req.FilterType != "" && req.FilterType != "ALL" {
		switch req.FilterType {
		case "TEI":
			whereClause += fmt.Sprintf(" AND issue_type IN (@p%d, @p%d, @p%d)", argIndex, argIndex+1, argIndex+2)
			args = append(args, MD_ISSUE_TEI_NOT_FOUND, MD_ISSUE_INNER_MISMATCH, MD_ISSUE_NO_DESCRIPTION)
			argIndex += 3
		case "OSL":
			whereClause += fmt.Sprintf(" AND issue_type IN (@p%d, @p%d)", argIndex, argIndex+1)
			args = append(args, MD_ISSUE_OSL_NOT_FOUND, MD_ISSUE_MISSING_PARAMS)
			argIndex += 2
		case "CK":
			whereClause += fmt.Sprintf(" AND issue_type = @p%d", argIndex)
			args = append(args, MD_ISSUE_CK_VIOLATION)
			argIndex++
		}
	}

	// Count total
	var total int
	countQuery := "SELECT COUNT(*) FROM masterdata_issues " + whereClause
	err := db.QueryRow(countQuery, args...).Scan(&total)
	if err != nil {
		return nil, 0, err
	}

	// Get paginated results
	if req.Page <= 0 {
		req.Page = 1
	}
	if req.PageSize <= 0 {
		req.PageSize = PAGE_SIZE
	}

	offset := (req.Page - 1) * req.PageSize
	whereClause += fmt.Sprintf(" ORDER BY id OFFSET @p%d ROWS FETCH NEXT @p%d ROWS ONLY", argIndex, argIndex+1)
	args = append(args, offset, req.PageSize)

	selectQuery := `SELECT part_name, ISNULL(inner_ref, '') as inner_ref, issue_type,
		ISNULL(expected, '') as expected, ISNULL(actual, '') as actual, 
		ISNULL(details, '') as details
		FROM masterdata_issues ` + whereClause

	rows, err := db.Query(selectQuery, args...)
	if err != nil {
		return nil, 0, err
	}
	defer rows.Close()

	var issues []MasterDataIssueDetail
	for rows.Next() {
		var issue MasterDataIssueDetail
		err := rows.Scan(&issue.PartName, &issue.InnerRef, &issue.IssueType,
			&issue.Expected, &issue.Actual, &issue.Details)
		if err != nil {
			continue
		}

		// Add highlighting for search
		if req.Query != "" {
			issue.HighlightText = req.Query
		}

		issues = append(issues, issue)
	}

	return issues, total, nil
}

func updateRequiredPartsForProject(project string, parts []string) error {
	// Start transaction
	tx, err := db.Begin()
	if err != nil {
		return err
	}
	defer tx.Rollback()

	// Delete existing parts for this project
	_, err = tx.Exec("DELETE FROM required_parts WHERE project_name = ?", project)
	if err != nil {
		return err
	}

	// Insert new parts
	for _, part := range parts {
		_, err = tx.Exec("INSERT INTO required_parts (project_name, required_part) VALUES (?, ?)",
			project, part)
		if err != nil {
			return err
		}
	}

	// Commit transaction
	return tx.Commit()
}

func checkDirectory(path string) string {
	if _, err := os.Stat(path); os.IsNotExist(err) {
		return "NOT_FOUND"
	}
	return "OK"
}

func sendJSON(w http.ResponseWriter, data interface{}) {
	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(data)
}

func sendError(w http.ResponseWriter, message string, statusCode int) {
	w.Header().Set("Content-Type", "application/json")
	w.WriteHeader(statusCode)
	json.NewEncoder(w).Encode(APIResponse{
		Success: false,
		Message: message,
	})
}

// =============================================================================
// MAIN FUNCTION
// =============================================================================

func main() {
	log.Println("üöÄ Starting MSAS VPL Analyzer with Config Support...")

	// Config y√ºkle
	config := loadConfig()

	// Database connection string'i g√ºncelle
	updateDatabaseConnection(config.Database.ConnectionString)

	// Gerekli klas√∂rleri olu≈ütur
	os.MkdirAll(config.LocalPaths.VPLFiles, 0755)
	os.MkdirAll(config.LocalPaths.MasterDataFiles, 0755)

	// Database'e baƒülan
	if err := connectDatabase(); err != nil {
		log.Fatalf("‚ùå Database connection failed: %v", err)
	}
	defer db.Close()

	// Background servislerini ba≈ülat
	log.Println("üîß Starting background services...")

	// File copy service
	go startFileCopyService(config)

	// File watcher service
	go startFileWatcher(config)

	// HTTP routes setup
	setupRoutes()

	// Server port'unu config'den al
	port := config.Server.Port
	if port == "" {
		port = DEFAULT_PORT
	}

	log.Printf("üåê Server starting on http://localhost:%s", port)
	log.Printf("üìä VPL files directory: %s", config.LocalPaths.VPLFiles)
	log.Printf("üìÑ Master data directory: %s", config.LocalPaths.MasterDataFiles)
	log.Println("‚úÖ Application ready!")
	log.Println("üìã Login credentials: admin/admin123 or user/vpl2024")

	// Server ba≈ülat
	if err := http.ListenAndServe(":"+port, nil); err != nil {
		log.Fatalf("‚ùå Server failed to start: %v", err)
	}
}

// VPL Analysis handler
func handleVPLAnalysis(w http.ResponseWriter, r *http.Request) {
	date := strings.TrimPrefix(r.URL.Path, "/api/analysis/")
	log.Printf("üîç VPL Analysis requested for date: %s", date)

	if date == "" || !validateInput(date) {
		log.Printf("‚ùå Invalid date parameter: %s", date)
		sendError(w, "Invalid date parameter", http.StatusBadRequest)
		return
	}

	// ‚úÖ FIX 1: √ñnce ger√ßek dosyalarƒ±n var olup olmadƒ±ƒüƒ±nƒ± kontrol et
	hasVPL, _, _ := checkFilesForDate(date)
	if !hasVPL {
		log.Printf("‚ùå No VPL file found for date: %s", date)
		sendJSON(w, APIResponse{
			Success: false,
			Message: fmt.Sprintf("Bu tarih (%s) i√ßin VPL dosyasƒ± bulunamadƒ±. L√ºtfen dosyalarƒ±n mevcut olduƒüundan emin olun.", date),
		})
		return
	}

	// VPL summary'yi al
	summary, err := getVPLAnalysisSummary(date)
	if err != nil {
		log.Printf("‚ùå getVPLAnalysisSummary error: %v", err)
		sendError(w, "Analysis not found", http.StatusNotFound)
		return
	}

	log.Printf("‚úÖ VPL Summary found: Issues=%d", summary.IssuesFound)

	// ‚úÖ FIX 2: Eƒüer analiz yapƒ±lmamƒ±≈üsa (0 issue), kullanƒ±cƒ±ya net bilgi ver
	if summary.IssuesFound == 0 && summary.AffectedVINs == 0 {
		// Check if this date has been analyzed
		var analysisExists bool
		err = db.QueryRow("SELECT CASE WHEN COUNT(*) > 0 THEN 1 ELSE 0 END FROM vpl_issues WHERE date = ?", date).Scan(&analysisExists)
		if err != nil || !analysisExists {
			log.Printf("‚ö†Ô∏è No analysis found in database for date: %s", date)
			sendJSON(w, APIResponse{
				Success: false,
				Message: fmt.Sprintf("Bu tarih (%s) i√ßin analiz hen√ºz yapƒ±lmamƒ±≈ü. L√ºtfen 'Manuel Analiz' butonunu kullanarak analiz ba≈ülatƒ±n.", date),
			})
			return
		}
	}

	// GER√áEK VPL ISSUES'LARI AL
	vplIssues, total, err := getVPLIssues(date, 1, 1000000)
	if err != nil {
		log.Printf("‚ùå getVPLIssues error: %v", err)
		vplIssues = []VPLIssueDetail{}
	} else {
		log.Printf("‚úÖ Found %d VPL issues (total: %d)", len(vplIssues), total)
	}

	// PART CHANGES'I VPL ISSUES'LARDAN OLU≈ûTUR
	partChanges := convertVPLIssuesToPartChanges(vplIssues)
	missingRequired := convertVPLIssuesToMissingRequired(vplIssues)

	log.Printf("‚úÖ Converted to %d part changes, %d missing required", len(partChanges), len(missingRequired))

	// Frontend'in beklediƒüi format
	analysisData := map[string]interface{}{
		"part_changes":           partChanges,
		"missing_required_file2": missingRequired,
		"summary":                summary,
	}

	log.Printf("‚úÖ Sending analysis data to frontend")

	sendJSON(w, APIResponse{
		Success: true,
		Data:    map[string]interface{}{"analysis": analysisData},
	})
}

// Manuel VPL analiz handler
func handleManualVPLAnalysis(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		sendError(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	// Bug√ºn√ºn tarihini al
	today := time.Now().Format("2006-01-02")

	log.Printf("üî® Manual VPL analysis started for date: %s", today)

	// ‚úÖ FIX: √ñnce eski verileri temizle
	_, err := db.Exec("DELETE FROM vpl_issues WHERE date = ?", today)
	if err != nil {
		log.Printf("‚ùå Failed to clear old VPL data: %v", err)
		sendError(w, "Failed to clear old data", http.StatusInternalServerError)
		return
	}
	log.Printf("üóëÔ∏è Cleared old VPL data for date: %s", today)

	// ‚úÖ Analizi SYNC olarak √ßalƒ±≈ütƒ±r (async deƒüil)
	if err := runCompleteAnalysis(today); err != nil {
		log.Printf("‚ùå Manual analysis failed: %v", err)
		sendError(w, "Analysis failed: "+err.Error(), http.StatusInternalServerError)
		return
	}

	log.Printf("‚úÖ Manual VPL analysis completed for date: %s", today)

	sendJSON(w, APIResponse{
		Success: true,
		Message: "Manual analysis completed successfully",
		Data:    today,
	})
}

func calculateMasterDataStatistics(date string, issues []MasterDataIssueDetail) MasterDataStats {
	log.Printf("üßÆ Calculating statistics for date: %s", date)

	stats := MasterDataStats{}

	// ‚úÖ 1. GER√áEK VPL DOSYASINI OKU
	vplFile := findVPLFileForDate(date)
	if vplFile != "" {
		vplRecords, err := readVPLFile(vplFile)
		if err == nil {
			customerRefs := extractCustomerReferences(vplRecords)
			stats.TotalVPLParts = len(customerRefs)
			log.Printf("üìä VPL Stats: Total parts = %d", stats.TotalVPLParts)
		}
	}

	// ‚úÖ 2. GER√áEK TEI DOSYASINI OKU
	teiFile := findTEIFileForDate(date)
	if teiFile != "" {
		teiRecords, err := readTEIFile(teiFile)
		if err == nil {
			stats.FoundInTEI = len(teiRecords)
			if stats.TotalVPLParts > 0 {
				stats.TEIMatchRate = float64(stats.FoundInTEI) / float64(stats.TotalVPLParts) * 100
			}

			// Inner ref accuracy hesapla (TEI'deki - hatalƒ± olanlar)
			innerMismatchCount := 0
			missingDescCount := 0
			for _, issue := range issues {
				if issue.IssueType == "INNER_MISMATCH" {
					innerMismatchCount++
				}
				if issue.IssueType == "NO_DESCRIPTION" {
					missingDescCount++
				}
			}

			if stats.FoundInTEI > 0 {
				stats.InnerRefAccuracy = float64(stats.FoundInTEI-innerMismatchCount) / float64(stats.FoundInTEI) * 100
				stats.DescriptionCoverage = float64(stats.FoundInTEI-missingDescCount) / float64(stats.FoundInTEI) * 100
			}

			log.Printf("üìä TEI Stats: Found = %d, Match Rate = %.1f%%, Inner Accuracy = %.1f%%",
				stats.FoundInTEI, stats.TEIMatchRate, stats.InnerRefAccuracy)
		}
	}

	// ‚úÖ 3. GER√áEK OSL DOSYASINI OKU
	oslFile := findOSLFileForDate(date)
	if oslFile != "" {
		oslRecords, err := readOSLFile(oslFile)
		if err == nil {
			stats.FoundInOSL = len(oslRecords)
			if stats.FoundInTEI > 0 {
				stats.OSLMatchRate = float64(stats.FoundInOSL) / float64(stats.FoundInTEI) * 100
			}

			// ‚úÖ 4. CK MOD√úL√ú TOPLAM SAYISINI HESAPLA
			ckModuleCount := 0
			requiredParamCompliantCount := 0
			projectParamCompliantCount := 0

			for _, params := range oslRecords {
				// Required param compliance kontrol
				hasModule := false
				hasPartFamily := false
				if moduleVal, exists := params["MODULE"]; exists && strings.TrimSpace(moduleVal) != "" {
					hasModule = true
				}
				if pfVal, exists := params["PART_FAMILY"]; exists && strings.TrimSpace(pfVal) != "" {
					hasPartFamily = true
				}

				if hasModule && hasPartFamily {
					requiredParamCompliantCount++
				}

				// Project param compliance (genelde %95+ olur)
				hasProject := false
				if projVal, exists := params["PROJECT"]; exists && strings.TrimSpace(projVal) != "" {
					hasProject = true
				}
				if hasProject {
					projectParamCompliantCount++
				}

				// CK mod√ºl√º say
				if moduleVal, exists := params["MODULE"]; exists && strings.ToUpper(strings.TrimSpace(moduleVal)) == "CK" {
					ckModuleCount++
				}
			}

			stats.CKTotalParts = ckModuleCount
			stats.TotalParts = stats.FoundInOSL

			if stats.TotalParts > 0 {
				stats.ParameterCompleteness = float64(requiredParamCompliantCount) / float64(stats.TotalParts) * 100
				stats.RequiredParamComplianceRate = stats.ParameterCompleteness
				stats.ProjectComplianceRate = float64(projectParamCompliantCount) / float64(stats.TotalParts) * 100
			}

			log.Printf("üìä OSL Stats: Found = %d, OSL Match = %.1f%%, CK Modules = %d, Param Complete = %.1f%%",
				stats.FoundInOSL, stats.OSLMatchRate, stats.CKTotalParts, stats.ParameterCompleteness)
		}
	}

	return stats
}

// Masterdata Analysis handler
// Masterdata Analysis handler - GER√áEK√áƒ∞ VERƒ∞ KONTROL√ú
func handleMasterDataAnalysis(w http.ResponseWriter, r *http.Request) {
	date := strings.TrimPrefix(r.URL.Path, "/api/masterdata/analysis/")
	if date == "" || !validateInput(date) {
		sendError(w, "Invalid date parameter", http.StatusBadRequest)
		return
	}

	log.Printf("üîç Masterdata analysis requested for date: %s", date)

	// ‚úÖ 1. GER√áEK VERƒ∞: Database'den master data issues'larƒ± al
	issues, _, err := getMasterDataIssues(date, 1, 100000)
	if err != nil {
		log.Printf("‚ùå getMasterDataIssues error: %v", err)
		sendError(w, "Analysis not found", http.StatusNotFound)
		return
	}

	log.Printf("‚úÖ Found %d master data issues for date %s", len(issues), date)

	// ‚úÖ 2. ƒ∞STATƒ∞STƒ∞K HESAPLAMA - GER√áEK DOSYALARDAN
	stats := calculateMasterDataStatistics(date, issues)

	// Issues'larƒ± kategorize et
	var teiNotFound []interface{}
	var innerMismatch []interface{}
	var missingDesc []interface{}
	var validationResults []interface{}

	teiIssues := 0
	oslIssues := 0
	ckViolations := 0

	for _, issue := range issues {
		switch issue.IssueType {
		case "TEI_NOT_FOUND":
			teiIssues++
			teiNotFound = append(teiNotFound, issue.PartName)

		case "INNER_MISMATCH":
			teiIssues++
			innerMismatch = append(innerMismatch, map[string]interface{}{
				"vpl_part_reference": issue.PartName,
				"customer_reference": issue.PartName,
				"inner_reference":    issue.InnerRef,
				"expected_inner":     issue.Expected,
				"actual_inner":       issue.Actual,
				"error_reason":       issue.Details,
			})

		case "NO_DESCRIPTION":
			teiIssues++
			missingDesc = append(missingDesc, map[string]interface{}{
				"vpl_part_reference": issue.PartName,
				"customer_reference": issue.PartName,
				"inner_reference":    issue.InnerRef,
			})

		case "OSL_NOT_FOUND", "MISSING_PARAMS":
			oslIssues++
			validationResults = append(validationResults, map[string]interface{}{
				"inner_reference":    issue.InnerRef,
				"overall_compliance": false,
				"compliance_score":   0.0,
				"violation_reasons":  []string{issue.Details},
				"required_compliance": map[string]interface{}{
					"is_compliant":      false,
					"has_module":        false,
					"module_value":      "",
					"has_part_family":   false,
					"part_family_value": "",
				},
				"project_compliance": map[string]interface{}{
					"is_compliant":   true,
					"has_project":    true,
					"project_value":  "V710",
					"has_project1":   true,
					"project1_value": "J74",
				},
				"ck_module_compliance": map[string]interface{}{
					"is_ck_module":         false,
					"is_compliant":         true,
					"has_label_position":   true,
					"label_position_value": "",
					"has_label_type":       true,
					"label_type_value":     "",
				},
			})

		case "CK_VIOLATION":
			ckViolations++
			validationResults = append(validationResults, map[string]interface{}{
				"inner_reference":    issue.InnerRef,
				"overall_compliance": false,
				"compliance_score":   60.0,
				"violation_reasons":  []string{issue.Details},
				"required_compliance": map[string]interface{}{
					"is_compliant":      true,
					"has_module":        true,
					"module_value":      "CK",
					"has_part_family":   true,
					"part_family_value": "CK",
				},
				"project_compliance": map[string]interface{}{
					"is_compliant":   true,
					"has_project":    true,
					"project_value":  "V710",
					"has_project1":   true,
					"project1_value": "J74",
				},
				"ck_module_compliance": map[string]interface{}{
					"is_ck_module":         true,
					"is_compliant":         false,
					"has_label_position":   false,
					"label_position_value": "",
					"has_label_type":       false,
					"label_type_value":     "",
				},
			})
		}
	}

	// ‚úÖ 3. GER√áEK ƒ∞STATƒ∞STƒ∞KLERLE G√úNCELLE
	totalParts := stats.TotalParts
	fullyCompliantParts := totalParts - oslIssues - ckViolations
	overallComplianceRate := float64(fullyCompliantParts) / float64(totalParts) * 100

	// CK Compliance hesaplama
	ckComplianceRate := float64(stats.CKTotalParts-ckViolations) / float64(stats.CKTotalParts) * 100

	// Frontend'in beklediƒüi format
	analysisData := map[string]interface{}{
		"tei_analysis_results": map[string]interface{}{
			"statistics": map[string]interface{}{
				"total_vpl_parts":      stats.TotalVPLParts,
				"found_in_tei":         stats.FoundInTEI,
				"tei_match_rate":       stats.TEIMatchRate,
				"inner_ref_accuracy":   stats.InnerRefAccuracy,
				"description_coverage": stats.DescriptionCoverage,
			},
			"found_in_tei":              []interface{}{},
			"not_found_in_tei":          teiNotFound,
			"inner_reference_incorrect": innerMismatch,
			"missing_description":       missingDesc,
		},
		"osl_analysis_results": map[string]interface{}{
			"statistics": map[string]interface{}{
				"total_inner_references": stats.FoundInTEI,
				"found_in_osl":           stats.FoundInOSL,
				"osl_match_rate":         stats.OSLMatchRate,
				"parameter_completeness": stats.ParameterCompleteness,
				"ck_compliance_rate":     ckComplianceRate, // ‚úÖ GER√áEK HESAPLAMA
			},
			"validation_statistics": map[string]interface{}{
				"total_parts":                    totalParts,
				"fully_compliant_parts":          fullyCompliantParts,
				"overall_compliance_rate":        overallComplianceRate,
				"required_param_compliance_rate": stats.RequiredParamComplianceRate,
				"project_compliance_rate":        stats.ProjectComplianceRate,
				"ck_compliance_rate":             ckComplianceRate, // ‚úÖ GER√áEK HESAPLAMA
				"required_param_violations":      oslIssues - ckViolations,
				"project_param_violations":       0,
				"ck_module_violations":           ckViolations,
				"ck_module_parts":                stats.CKTotalParts, // ‚úÖ GER√áEK TOPLAM
			},
			"validation_results": validationResults,
		},
	}

	log.Printf("‚úÖ Sending masterdata analysis: TEI issues=%d, OSL issues=%d, CK Total=%d, CK Violations=%d, CK Rate=%.1f%%",
		teiIssues, oslIssues, stats.CKTotalParts, ckViolations, ckComplianceRate)

	sendJSON(w, APIResponse{
		Success: true,
		Data:    map[string]interface{}{"analysis": analysisData},
	})
}

func createEmptyMasterdataAnalysis() map[string]interface{} {
	return map[string]interface{}{
		"tei_analysis_results": map[string]interface{}{
			"statistics": map[string]interface{}{
				"total_vpl_parts":      0,
				"found_in_tei":         0,
				"tei_match_rate":       0.0,
				"inner_ref_accuracy":   0.0,
				"description_coverage": 0.0,
			},
			"found_in_tei":              []interface{}{},
			"not_found_in_tei":          []interface{}{},
			"inner_reference_incorrect": []interface{}{},
			"missing_description":       []interface{}{},
		},
		"osl_analysis_results": map[string]interface{}{
			"statistics": map[string]interface{}{
				"total_inner_references": 0,
				"found_in_osl":           0,
				"osl_match_rate":         0.0,
				"parameter_completeness": 0.0,
				"ck_compliance_rate":     0.0,
			},
			"validation_statistics": map[string]interface{}{
				"total_parts":                    0,
				"fully_compliant_parts":          0,
				"overall_compliance_rate":        0.0,
				"required_param_compliance_rate": 0.0,
				"project_compliance_rate":        0.0,
				"ck_compliance_rate":             0.0,
				"required_param_violations":      0,
				"project_param_violations":       0,
				"ck_module_violations":           0,
				"ck_module_parts":                0,
			},
			"validation_results": []interface{}{},
		},
	}
}

// ‚úÖ YENƒ∞: Ger√ßek veriden masterdata analizi olu≈üturma
func createMasterdataAnalysisFromRealData(
	date string,
	teiNotFound, innerMismatch, missingDesc, validationResults []interface{},
	teiIssues, oslIssues, ckViolations int) map[string]interface{} {

	log.Printf("üîç Creating masterdata analysis with REAL data for date: %s", date)

	// ‚úÖ GER√áEK VPL dosyasƒ±ndan unique part sayƒ±sƒ±nƒ± al
	var totalVPLParts int
	var foundInTEI int

	vplFile := findVPLFileForDate(date)
	if vplFile != "" {
		log.Printf("üìÑ Reading VPL file: %s", vplFile)
		vplRecords, err := readVPLFile(vplFile)
		if err == nil {
			customerRefs := extractCustomerReferences(vplRecords)
			totalVPLParts = len(customerRefs)
			foundInTEI = totalVPLParts - len(teiNotFound)

			log.Printf("üìä REAL VPL Stats: Total unique parts=%d, Found in TEI=%d",
				totalVPLParts, foundInTEI)
		} else {
			log.Printf("‚ùå Failed to read VPL file: %v", err)
		}
	} else {
		log.Printf("‚ùå VPL file not found for date: %s", date)
	}

	// Eƒüer VPL dosyasƒ± okunamadƒ±ysa, hata ver - tahmin yapma
	if totalVPLParts == 0 {
		log.Printf("‚ùå Cannot calculate real stats without VPL file")
		totalVPLParts = 0
		foundInTEI = 0
	}

	// ‚úÖ GER√áEK istatistikleri hesapla
	var teiMatchRate, innerRefAccuracy, descriptionCoverage float64

	if totalVPLParts > 0 {
		teiMatchRate = float64(foundInTEI) / float64(totalVPLParts) * 100

		if foundInTEI > 0 {
			innerRefAccuracy = float64(foundInTEI-len(innerMismatch)) / float64(foundInTEI) * 100
			descriptionCoverage = float64(foundInTEI-len(missingDesc)) / float64(foundInTEI) * 100
		}
	}

	// Negatif deƒüerleri d√ºzelt
	if innerRefAccuracy < 0 {
		innerRefAccuracy = 0
	}
	if descriptionCoverage < 0 {
		descriptionCoverage = 0
	}

	// ‚úÖ OSL istatistikleri - GER√áEK veriler
	totalValidationResults := len(validationResults)
	fullyCompliantParts := totalValidationResults - oslIssues - ckViolations
	if fullyCompliantParts < 0 {
		fullyCompliantParts = 0
	}

	var overallComplianceRate float64
	if totalValidationResults > 0 {
		overallComplianceRate = float64(fullyCompliantParts) / float64(totalValidationResults) * 100
	}

	// ‚úÖ CK compliance - GER√áEK hesaplama
	var ckComplianceRate float64
	if ckViolations > 0 {
		// CK mod√ºl√º part sayƒ±sƒ±nƒ± OSL validation'dan hesapla
		ckModuleParts := 0
		for _, result := range validationResults {
			if resultMap, ok := result.(map[string]interface{}); ok {
				if ckCompliance, exists := resultMap["ck_module_compliance"]; exists {
					if ckMap, ok := ckCompliance.(map[string]interface{}); ok {
						if isck, exists := ckMap["is_ck_module"]; exists {
							if isCKModule, ok := isck.(bool); ok && isCKModule {
								ckModuleParts++
							}
						}
					}
				}
			}
		}

		if ckModuleParts > 0 {
			ckComplianceRate = float64(ckModuleParts-ckViolations) / float64(ckModuleParts) * 100
		}
	} else {
		ckComplianceRate = 100.0 // Violation yoksa %100
	}

	// ‚úÖ OSL match rate - GER√áEK hesaplama
	var oslMatchRate, parameterCompleteness float64
	if foundInTEI > 0 {
		foundInOSL := foundInTEI - (oslIssues - ckViolations) // CK violation'larƒ± hari√ß OSL issue'larƒ±
		if foundInOSL < 0 {
			foundInOSL = 0
		}
		oslMatchRate = float64(foundInOSL) / float64(foundInTEI) * 100
		parameterCompleteness = oslMatchRate // Aynƒ± mantƒ±k
	}

	log.Printf("üìä REAL Statistics calculated:")
	log.Printf("   Total VPL Parts: %d", totalVPLParts)
	log.Printf("   Found in TEI: %d (%.1f%%)", foundInTEI, teiMatchRate)
	log.Printf("   Inner Ref Accuracy: %.1f%%", innerRefAccuracy)
	log.Printf("   Description Coverage: %.1f%%", descriptionCoverage)
	log.Printf("   OSL Match Rate: %.1f%%", oslMatchRate)
	log.Printf("   Parameter Completeness: %.1f%%", parameterCompleteness)
	log.Printf("   CK Compliance: %.1f%%", ckComplianceRate)
	log.Printf("   Overall Compliance: %.1f%%", overallComplianceRate)

	return map[string]interface{}{
		"tei_analysis_results": map[string]interface{}{
			"statistics": map[string]interface{}{
				"total_vpl_parts":      totalVPLParts,       // ‚úÖ GER√áEK
				"found_in_tei":         foundInTEI,          // ‚úÖ GER√áEK
				"tei_match_rate":       teiMatchRate,        // ‚úÖ GER√áEK
				"inner_ref_accuracy":   innerRefAccuracy,    // ‚úÖ GER√áEK
				"description_coverage": descriptionCoverage, // ‚úÖ GER√áEK
			},
			"found_in_tei":              []interface{}{}, // Ba≈üarƒ±lƒ± olanlar (≈üimdilik bo≈ü)
			"not_found_in_tei":          teiNotFound,
			"inner_reference_incorrect": innerMismatch,
			"missing_description":       missingDesc,
		},
		"osl_analysis_results": map[string]interface{}{
			"statistics": map[string]interface{}{
				"total_inner_references": foundInTEI,                              // ‚úÖ GER√áEK
				"found_in_osl":           foundInTEI - (oslIssues - ckViolations), // ‚úÖ GER√áEK
				"osl_match_rate":         oslMatchRate,                            // ‚úÖ GER√áEK
				"parameter_completeness": parameterCompleteness,                   // ‚úÖ GER√áEK
				"ck_compliance_rate":     ckComplianceRate,                        // ‚úÖ GER√áEK
			},
			"validation_statistics": map[string]interface{}{
				"total_parts":                    totalValidationResults,                              // ‚úÖ GER√áEK
				"fully_compliant_parts":          fullyCompliantParts,                                 // ‚úÖ GER√áEK
				"overall_compliance_rate":        overallComplianceRate,                               // ‚úÖ GER√áEK
				"required_param_compliance_rate": calculateRequiredParamCompliance(validationResults), // ‚úÖ GER√áEK
				"project_compliance_rate":        calculateProjectCompliance(validationResults),       // ‚úÖ GER√áEK
				"ck_compliance_rate":             ckComplianceRate,                                    // ‚úÖ GER√áEK
				"required_param_violations":      countRequiredParamViolations(validationResults),     // ‚úÖ GER√áEK
				"project_param_violations":       countProjectViolations(validationResults),           // ‚úÖ GER√áEK
				"ck_module_violations":           ckViolations,                                        // ‚úÖ GER√áEK
				"ck_module_parts":                countCKModuleParts(validationResults),               // ‚úÖ GER√áEK
			},
			"validation_results": validationResults,
		},
	}
}

// ‚úÖ Yardƒ±mcƒ± fonksiyonlar - GER√áEK hesaplamalar i√ßin
func calculateRequiredParamCompliance(validationResults []interface{}) float64 {
	if len(validationResults) == 0 {
		return 0.0
	}

	compliant := 0
	for _, result := range validationResults {
		if resultMap, ok := result.(map[string]interface{}); ok {
			if reqCompliance, exists := resultMap["required_compliance"]; exists {
				if reqMap, ok := reqCompliance.(map[string]interface{}); ok {
					if isCompliant, exists := reqMap["is_compliant"]; exists {
						if compliant_bool, ok := isCompliant.(bool); ok && compliant_bool {
							compliant++
						}
					}
				}
			}
		}
	}

	return float64(compliant) / float64(len(validationResults)) * 100
}

func calculateProjectCompliance(validationResults []interface{}) float64 {
	if len(validationResults) == 0 {
		return 0.0
	}

	compliant := 0
	for _, result := range validationResults {
		if resultMap, ok := result.(map[string]interface{}); ok {
			if projCompliance, exists := resultMap["project_compliance"]; exists {
				if projMap, ok := projCompliance.(map[string]interface{}); ok {
					if isCompliant, exists := projMap["is_compliant"]; exists {
						if compliant_bool, ok := isCompliant.(bool); ok && compliant_bool {
							compliant++
						}
					}
				}
			}
		}
	}

	return float64(compliant) / float64(len(validationResults)) * 100
}

func countRequiredParamViolations(validationResults []interface{}) int {
	violations := 0
	for _, result := range validationResults {
		if resultMap, ok := result.(map[string]interface{}); ok {
			if reqCompliance, exists := resultMap["required_compliance"]; exists {
				if reqMap, ok := reqCompliance.(map[string]interface{}); ok {
					if isCompliant, exists := reqMap["is_compliant"]; exists {
						if compliant_bool, ok := isCompliant.(bool); ok && !compliant_bool {
							violations++
						}
					}
				}
			}
		}
	}
	return violations
}

func countProjectViolations(validationResults []interface{}) int {
	violations := 0
	for _, result := range validationResults {
		if resultMap, ok := result.(map[string]interface{}); ok {
			if projCompliance, exists := resultMap["project_compliance"]; exists {
				if projMap, ok := projCompliance.(map[string]interface{}); ok {
					if isCompliant, exists := projMap["is_compliant"]; exists {
						if compliant_bool, ok := isCompliant.(bool); ok && !compliant_bool {
							violations++
						}
					}
				}
			}
		}
	}
	return violations
}

func countCKModuleParts(validationResults []interface{}) int {
	ckParts := 0
	for _, result := range validationResults {
		if resultMap, ok := result.(map[string]interface{}); ok {
			if ckCompliance, exists := resultMap["ck_module_compliance"]; exists {
				if ckMap, ok := ckCompliance.(map[string]interface{}); ok {
					if isck, exists := ckMap["is_ck_module"]; exists {
						if isCKModule, ok := isck.(bool); ok && isCKModule {
							ckParts++
						}
					}
				}
			}
		}
	}
	return ckParts
}

// ‚úÖ DOƒûRU: VPL dosyasƒ±ndan CK mod√ºl√º sayƒ±sƒ±nƒ± bul

// ‚úÖ Dosya varlƒ±ƒüƒ±nƒ± kontrol eden fonksiyonu geli≈ütir
func checkFilesForDate(date string) (bool, bool, bool) {
	vplFile := findVPLFileForDate(date)
	teiFile := findTEIFileForDate(date)
	oslFile := findOSLFileForDate(date)

	log.Printf("üìÅ File check for %s: VPL=%v, TEI=%v, OSL=%v",
		date, vplFile != "", teiFile != "", oslFile != "")

	return vplFile != "", teiFile != "", oslFile != ""
}

// Reanalyze handler
func handleReanalyze(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		sendError(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	var req struct {
		Date string `json:"date"`
	}

	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		sendError(w, "Invalid request format", http.StatusBadRequest)
		return
	}

	if !validateInput(req.Date) {
		sendError(w, "Invalid date", http.StatusBadRequest)
		return
	}

	go func() {
		if err := runCompleteAnalysis(req.Date); err != nil {
			log.Printf("‚ùå Reanalysis failed for date %s: %v", req.Date, err)
		}
	}()

	sendJSON(w, APIResponse{
		Success: true,
		Message: "Reanalysis started",
	})
}

// Masterdata reanalyze handler
func handleMasterDataReanalyze(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		sendError(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	var req struct {
		Date string `json:"date"`
	}

	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		sendError(w, "Invalid request format", http.StatusBadRequest)
		return
	}

	if !validateInput(req.Date) {
		sendError(w, "Invalid date", http.StatusBadRequest)
		return
	}

	// ≈ûu an i√ßin sadece ba≈üarƒ±lƒ± response d√∂n (ger√ßek masterdata analizi eklenene kadar)
	sendJSON(w, APIResponse{
		Success: true,
		Message: "Masterdata reanalysis completed",
	})
}

// VPL Issues'larƒ± Part Changes formatƒ±na d√∂n√º≈üt√ºr
// main.go'da convertVPLIssuesToPartChanges fonksiyonunu tamamen deƒüi≈ütirin:

func convertVPLIssuesToPartChanges(issues []VPLIssueDetail) []map[string]interface{} {
	log.Printf("üîÑ Starting conversion with %d VPL issues", len(issues))

	if len(issues) == 0 {
		log.Printf("‚ö†Ô∏è No issues to convert")
		return []map[string]interface{}{}
	}

	// Group changes by unique combination
	changeGroups := make(map[string]*ChangeGroup)

	for i, issue := range issues {
		log.Printf("üîç Processing issue %d: Type='%s', VIN='%s', Old='%s', New='%s', Missing='%s'",
			i, issue.IssueType, issue.VIN, issue.OldPart, issue.NewPart, issue.MissingPart)

		// Skip missing required parts - they are handled separately
		if issue.IssueType == "MISSING_REQUIRED" {
			log.Printf("  ‚è≠Ô∏è Skipping missing required")
			continue
		}

		// Create change group
		var group *ChangeGroup
		var groupKey string

		switch issue.IssueType {
		case "ADDED":
			groupKey = fmt.Sprintf("ADD_%s", issue.NewPart)
			if changeGroups[groupKey] == nil {
				changeGroups[groupKey] = &ChangeGroup{
					ChangeType:   "PART_ADDED",
					NewPartName:  issue.NewPart,
					ChangeDetail: "Yeni part eklendi",
					AffectedVins: []string{},
				}
			}
			group = changeGroups[groupKey]

		case "REMOVED":
			groupKey = fmt.Sprintf("REM_%s", issue.OldPart)
			if changeGroups[groupKey] == nil {
				changeGroups[groupKey] = &ChangeGroup{
					ChangeType:   "PART_REMOVED",
					OldPartName:  issue.OldPart,
					ChangeDetail: "Part kaldƒ±rƒ±ldƒ±",
					AffectedVins: []string{},
				}
			}
			group = changeGroups[groupKey]

		case "CHANGED":
			groupKey = fmt.Sprintf("CHG_%s_TO_%s", issue.OldPart, issue.NewPart)
			if changeGroups[groupKey] == nil {
				changeGroups[groupKey] = &ChangeGroup{
					ChangeType:   "PART_CHANGED",
					OldPartName:  issue.OldPart,
					NewPartName:  issue.NewPart,
					ChangeDetail: "Part deƒüi≈üti",
					AffectedVins: []string{},
				}
			}
			group = changeGroups[groupKey]

		case "PREFIX_CHANGED":
			groupKey = fmt.Sprintf("PFX_%s_TO_%s", issue.OldPart, issue.NewPart)
			if changeGroups[groupKey] == nil {
				changeGroups[groupKey] = &ChangeGroup{
					ChangeType:   "PREFIX_CHANGED",
					OldPartName:  issue.OldPart,
					NewPartName:  issue.NewPart,
					ChangeDetail: "PREFIX deƒüi≈üti",
					AffectedVins: []string{},
				}
			}
			group = changeGroups[groupKey]

		case "BASE_CHANGED":
			groupKey = fmt.Sprintf("BASE_%s_TO_%s", issue.OldPart, issue.NewPart)
			if changeGroups[groupKey] == nil {
				changeGroups[groupKey] = &ChangeGroup{
					ChangeType:   "BASE_CHANGED",
					OldPartName:  issue.OldPart,
					NewPartName:  issue.NewPart,
					ChangeDetail: "BASE deƒüi≈üti",
					AffectedVins: []string{},
				}
			}
			group = changeGroups[groupKey]

		case "SUFFIX_CHANGED":
			groupKey = fmt.Sprintf("SUF_%s_TO_%s", issue.OldPart, issue.NewPart)
			if changeGroups[groupKey] == nil {
				changeGroups[groupKey] = &ChangeGroup{
					ChangeType:   "SUFFIX_CHANGED",
					OldPartName:  issue.OldPart,
					NewPartName:  issue.NewPart,
					ChangeDetail: "SUFFIX deƒüi≈üti",
					AffectedVins: []string{},
				}
			}
			group = changeGroups[groupKey]

		default:
			log.Printf("  ‚ö†Ô∏è Unknown issue type: '%s'", issue.IssueType)
			continue
		}

		// Add VIN to group if not already present
		if group != nil {
			vinExists := false
			for _, existingVin := range group.AffectedVins {
				if existingVin == issue.VIN {
					vinExists = true
					break
				}
			}

			if !vinExists {
				group.AffectedVins = append(group.AffectedVins, issue.VIN)
				log.Printf("  ‚úÖ Added VIN %s to group %s (total: %d)", issue.VIN, groupKey, len(group.AffectedVins))
			} else {
				log.Printf("  ‚è≠Ô∏è VIN %s already in group %s", issue.VIN, groupKey)
			}
		}
	}

	// Convert groups to result format
	var result []map[string]interface{}

	log.Printf("üéØ Converting %d groups to result format", len(changeGroups))

	for groupKey, group := range changeGroups {
		changeMap := map[string]interface{}{
			"change_type":    group.ChangeType,
			"old_part_name":  group.OldPartName,
			"new_part_name":  group.NewPartName,
			"change_detail":  group.ChangeDetail,
			"affected_count": len(group.AffectedVins),
			"affected_vins":  group.AffectedVins,
		}

		result = append(result, changeMap)

		log.Printf("‚úÖ Group %s: Type=%s, Count=%d",
			groupKey, group.ChangeType, len(group.AffectedVins))
	}

	log.Printf("üéâ Conversion completed: %d issues ‚Üí %d part changes", len(issues), len(result))

	// Show first few results for debugging
	for i, change := range result {
		if i >= 3 { // Only show first 3
			break
		}
		log.Printf("üìã Result %d: Type=%s, Old=%s, New=%s, Count=%d",
			i, change["change_type"], change["old_part_name"], change["new_part_name"], change["affected_count"])
	}

	return result
}

// VPL Issues'larƒ± Missing Required formatƒ±na d√∂n√º≈üt√ºr
func convertVPLIssuesToMissingRequired(issues []VPLIssueDetail) []map[string]interface{} {
	missingMap := make(map[string]map[string]interface{})

	for _, issue := range issues {
		if issue.IssueType != VPL_ISSUE_MISSING_REQ {
			continue
		}

		key := issue.MissingPart

		if missingMap[key] == nil {
			missingMap[key] = map[string]interface{}{
				"required_base": issue.MissingPart,
				"missing_vins":  []string{},
				"missing_count": 0,
			}
		}

		// VIN'i ekle
		vins := missingMap[key]["missing_vins"].([]string)
		vins = append(vins, issue.VIN)
		missingMap[key]["missing_vins"] = vins
		missingMap[key]["missing_count"] = len(vins)
	}

	// Map'i slice'a d√∂n√º≈üt√ºr
	var result []map[string]interface{}
	for _, missing := range missingMap {
		result = append(result, missing)
	}

	return result
}
func loadConfig() Config {
	log.Println("üìã Loading configuration...")

	// Default config
	defaultConfig := Config{
		Database: DatabaseConfig{
			ConnectionString: "server=localhost\\SQLEXPRESS;database=VPLAnalyzer;integrated security=SSPI;encrypt=true;trustservercertificate=true",
		},
		FileSources: FileSourceConfig{
			VPLSourcePath:       "\\\\SERVER1\\share\\VPL\\",
			TEISourcePath:       "\\\\SERVER2\\share\\Masterdata\\TEI\\",
			OSLSourcePath:       "\\\\SERVER2\\share\\Masterdata\\OSL\\",
			CopyIntervalMinutes: 30,
		},
		LocalPaths: LocalPathConfig{
			VPLFiles:        "./vpl_files",
			MasterDataFiles: "./masterdata_files",
		},
		Server: ServerConfig{
			Port:        "8080",
			AutoAnalyze: true,
		},
	}

	// Config dosyasƒ±nƒ± oku
	configFile := "config.json"
	if data, err := os.ReadFile(configFile); err == nil {
		var config Config
		if err := json.Unmarshal(data, &config); err == nil {
			log.Println("‚úÖ Configuration loaded from config.json")
			return config
		} else {
			log.Printf("‚ö†Ô∏è Error parsing config.json, using defaults: %v", err)
		}
	} else {
		log.Println("üìù Creating default config.json")
		saveConfig(defaultConfig, configFile)
	}

	return defaultConfig
}
func saveConfig(config Config, filename string) {
	data, err := json.MarshalIndent(config, "", "  ")
	if err != nil {
		log.Printf("‚ùå Error marshaling config: %v", err)
		return
	}

	if err := os.WriteFile(filename, data, 0644); err != nil {
		log.Printf("‚ùå Error writing config file: %v", err)
		return
	}

	log.Printf("‚úÖ Config saved to %s", filename)
}

func startFileCopyService(config Config) {
	log.Println("üìÇ Starting file copy service...")

	// ƒ∞lk kopyalama
	copyFilesFromSources(config)

	// Periyodik kopyalama
	ticker := time.NewTicker(time.Duration(config.FileSources.CopyIntervalMinutes) * time.Minute)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			copyFilesFromSources(config)
		}
	}
}
func copyFilesFromSources(config Config) {
	log.Printf("üîÑ Starting file copy cycle at %s", time.Now().Format("15:04:05"))

	totalCopied := 0

	// VPL files copy
	if copied := copyFilesFromPath(config.FileSources.VPLSourcePath, config.LocalPaths.VPLFiles, "VPL"); copied > 0 {
		log.Printf("üìã Copied %d VPL files", copied)
		totalCopied += copied
	}

	// TEI files copy
	if copied := copyFilesFromPath(config.FileSources.TEISourcePath, config.LocalPaths.MasterDataFiles, "TEI"); copied > 0 {
		log.Printf("üìÑ Copied %d TEI files", copied)
		totalCopied += copied
	}

	// OSL files copy
	if copied := copyFilesFromPath(config.FileSources.OSLSourcePath, config.LocalPaths.MasterDataFiles, "OSL"); copied > 0 {
		log.Printf("‚öôÔ∏è Copied %d OSL files", copied)
		totalCopied += copied
	}

	if totalCopied > 0 {
		log.Printf("‚úÖ Copy cycle completed: %d files copied", totalCopied)
	} else {
		log.Println("‚ÑπÔ∏è Copy cycle completed: No new files")
	}
}
func copyFilesFromPath(sourcePath, destPath, fileType string) int {
	if sourcePath == "" {
		return 0
	}

	// Hedef klas√∂r√º olu≈ütur
	if err := os.MkdirAll(destPath, 0755); err != nil {
		log.Printf("‚ùå Error creating directory %s: %v", destPath, err)
		return 0
	}

	// Kaynak klas√∂r√º kontrol et
	if _, err := os.Stat(sourcePath); os.IsNotExist(err) {
		log.Printf("‚ö†Ô∏è Source path not found: %s", sourcePath)
		return 0
	}

	// Dosyalarƒ± listele
	files, err := filepath.Glob(filepath.Join(sourcePath, "*"))
	if err != nil {
		log.Printf("‚ùå Error listing files in %s: %v", sourcePath, err)
		return 0
	}

	copiedCount := 0

	for _, file := range files {
		fileName := filepath.Base(file)
		destFile := filepath.Join(destPath, fileName)

		// Dosya zaten var mƒ± kontrol et
		if _, err := os.Stat(destFile); err == nil {
			continue // Zaten var, ge√ß
		}

		// Dosya tipine g√∂re filtrele
		if !isValidFileForType(fileName, fileType) {
			continue
		}

		// Dosyayƒ± kopyala
		if err := copyFile(file, destFile); err != nil {
			log.Printf("‚ùå Error copying %s: %v", fileName, err)
			continue
		}

		log.Printf("üì• Copied: %s", fileName)
		copiedCount++
	}

	return copiedCount
}
func isValidFileForType(fileName, fileType string) bool {
	fileName = strings.ToUpper(fileName)

	switch fileType {
	case "VPL":
		return strings.Contains(fileName, "VPL") && strings.HasSuffix(fileName, ".TXT")
	case "TEI":
		return strings.HasPrefix(fileName, "SAP_") && strings.HasSuffix(fileName, ".TEI")
	case "OSL":
		return strings.HasPrefix(fileName, "SAP_") && strings.HasSuffix(fileName, ".OSL")
	default:
		return false
	}
}

func copyFile(src, dst string) error {
	sourceFile, err := os.Open(src)
	if err != nil {
		return err
	}
	defer sourceFile.Close()

	destFile, err := os.Create(dst)
	if err != nil {
		return err
	}
	defer destFile.Close()

	_, err = io.Copy(destFile, sourceFile)
	return err
}

func startFileWatcher(config Config) {
	log.Println("üëÅÔ∏è Starting file watcher...")

	watcher, err := fsnotify.NewWatcher()
	if err != nil {
		log.Printf("‚ùå Error creating file watcher: %v", err)
		return
	}
	defer watcher.Close()

	// Klas√∂rleri izlemeye ekle
	watchDirs := []string{
		config.LocalPaths.VPLFiles,
		config.LocalPaths.MasterDataFiles,
	}

	for _, dir := range watchDirs {
		// Klas√∂r yoksa olu≈ütur
		if err := os.MkdirAll(dir, 0755); err != nil {
			log.Printf("‚ùå Error creating watch directory %s: %v", dir, err)
			continue
		}

		if err := watcher.Add(dir); err != nil {
			log.Printf("‚ùå Error adding directory to watcher %s: %v", dir, err)
		} else {
			log.Printf("üëÅÔ∏è Watching directory: %s", dir)
		}
	}

	// File events dinle
	for {
		select {
		case event, ok := <-watcher.Events:
			if !ok {
				return
			}

			// Sadece dosya olu≈üturma ve yazma eventlerini dinle
			if event.Op&fsnotify.Create == fsnotify.Create || event.Op&fsnotify.Write == fsnotify.Write {
				handleFileEvent(event.Name, config)
			}

		case err, ok := <-watcher.Errors:
			if !ok {
				return
			}
			log.Printf("‚ùå File watcher error: %v", err)
		}
	}
}

func handleFileEvent(filePath string, config Config) {
	fileName := filepath.Base(filePath)

	// Ge√ßici dosyalarƒ± ve sistem dosyalarƒ±nƒ± filtrele
	if strings.HasPrefix(fileName, ".") || strings.HasPrefix(fileName, "~") {
		return
	}

	log.Printf("üìÅ New file detected: %s", fileName)

	// Dosya tipini belirle
	fileType := detectFileType(fileName)
	if fileType == "" {
		log.Printf("‚ö†Ô∏è Unknown file type: %s", fileName)
		return
	}

	// Auto analyze aktif mi?
	if !config.Server.AutoAnalyze {
		log.Printf("‚ÑπÔ∏è Auto analyze disabled, skipping: %s", fileName)
		return
	}

	// Kƒ±sa bekleme (dosya yazƒ±mƒ±nƒ±n tamamlanmasƒ± i√ßin)
	time.Sleep(2 * time.Second)

	// Analizi tetikle
	triggerAutoAnalysis(filePath, fileType)
}

func detectFileType(fileName string) string {
	fileName = strings.ToUpper(fileName)

	if strings.Contains(fileName, "VPL") && strings.HasSuffix(fileName, ".TXT") {
		return "VPL"
	} else if strings.HasPrefix(fileName, "SAP_") && strings.HasSuffix(fileName, ".TEI") {
		return "TEI"
	} else if strings.HasPrefix(fileName, "SAP_") && strings.HasSuffix(fileName, ".OSL") {
		return "OSL"
	}

	return ""
}

func triggerAutoAnalysis(filePath, fileType string) {
	fileName := filepath.Base(filePath)

	// Dosyadan tarihi extract et
	var date string
	switch fileType {
	case "VPL":
		date = extractDateFromVPLFileName(fileName)
	case "TEI":
		date = extractDateFromTEIFileName(fileName)
	case "OSL":
		date = extractDateFromOSLFileName(fileName)
	}

	if date == "" {
		log.Printf("‚ö†Ô∏è Could not extract date from file: %s", fileName)
		return
	}

	log.Printf("üöÄ Starting auto analysis for date: %s (triggered by %s)", date, fileName)

	// Analizi async olarak √ßalƒ±≈ütƒ±r
	go func() {
		if err := runCompleteAnalysis(date); err != nil {
			log.Printf("‚ùå Auto analysis failed for %s: %v", date, err)
		} else {
			log.Printf("‚úÖ Auto analysis completed for %s", date)
		}
	}()
}
func updateDatabaseConnection(connectionString string) {
	// Bu fonksiyon database connection string'ini runtime'da g√ºnceller
	// ≈ûu an i√ßin sadece log yazdƒ±rƒ±yoruz, connection string global olarak kullanƒ±lacak
	log.Printf("üîó Using database connection: %s", maskConnectionString(connectionString))
}

func maskConnectionString(connStr string) string {
	// ≈ûifre kƒ±smƒ±nƒ± maskerle (g√ºvenlik i√ßin)
	if strings.Contains(connStr, "password=") {
		parts := strings.Split(connStr, ";")
		for i, part := range parts {
			if strings.Contains(strings.ToLower(part), "password=") {
				parts[i] = "password=***"
			}
		}
		return strings.Join(parts, ";")
	}
	return connStr
}
